{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"loss.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPfBEGWDcNYO5SX+13EUpuw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"evEa2g2J4tlg"},"source":["import torch\n","import tensorflow as tf\n","import numpy as np\n","from main.smpl import Smpl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sLA32ATF7Eev"},"source":["def smpl2vertices(pose_and_shape, **kwargs):\n","    smpl = Smpl()\n","    vertices, joints_3d, rotations = smpl(pose_and_shape, **kwargs)    # transform the pose and shape parameter to SMPL vertices\n","    shapes = pose_and_shape[:, -10:] # NUM_SHAPE_PARAMS = 10\n","\n","    return tf.tuple([vertices, joints_3d, shapes])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_UPYVbnb3KQF"},"source":["def batch_align_by_pelvis(kp3d):\n","    left_id, right_id = 3, 0\n","    pelvis = (kp3d[:, left_id, :] + kp3d[:, right_id, :]) / 2.\n","    return kp3d - tf.expand_dims(pelvis, axis=1)\n","\n","def batch_compute_similarity_transform(real_kp3d, pred_kp3d):\n","    # transpose to [batch x 3 x K]\n","    real_kp3d = tf.transpose(real_kp3d, perm=[0, 2, 1])\n","    pred_kp3d = tf.transpose(pred_kp3d, perm=[0, 2, 1])\n","\n","    # 1. Remove mean.\n","    mean_real = tf.reduce_mean(real_kp3d, axis=2, keepdims=True)\n","    mean_pred = tf.reduce_mean(pred_kp3d, axis=2, keepdims=True)\n","\n","    centered_real = real_kp3d - mean_real\n","    centered_pred = pred_kp3d - mean_pred\n","\n","    # 2. Compute variance of centered_real used for scale.\n","    variance = tf.reduce_sum(centered_pred ** 2, axis=[-2, -1], keepdims=True)\n","\n","    # 3. The outer product of centered_real and centered_pred.\n","    K = tf.matmul(centered_pred, centered_real, transpose_b=True)\n","\n","    # 4. Solution that Maximizes trace(R'K) is R=s*V', where s, V are\n","    # singular vectors of K.\n","    with tf.device('/CPU:0'):\n","        # SVD is terrifyingly slow on GPUs, use cpus for this. Makes it a lot faster.\n","        s, u, v = tf.linalg.svd(K, full_matrices=True)\n","\n","        # Construct identity that fixes the orientation of R to get det(R)=1.\n","        det = tf.sign(tf.linalg.det(tf.matmul(u, v, transpose_b=True)))\n","\n","    det = tf.expand_dims(tf.expand_dims(det, -1), -1)\n","    shape = tf.shape(u)\n","    identity = tf.eye(shape[1], batch_shape=[shape[0]])\n","    identity = identity * det\n","\n","    # Construct R.\n","    R = tf.matmul(v, tf.matmul(identity, u, transpose_b=True))\n","\n","    # 5. Recover scale.\n","    trace = tf.linalg.trace(tf.matmul(R, K))\n","    trace = tf.expand_dims(tf.expand_dims(trace, -1), -1)\n","    scale = trace / variance\n","\n","    # 6. Recover translation.\n","    trans = mean_real - scale * tf.matmul(R, mean_pred)\n","\n","    # 7. Align\n","    aligned_kp3d = scale * tf.matmul(R, pred_kp3d) + trans\n","\n","    return tf.transpose(aligned_kp3d, perm=[0, 2, 1])\n","\n","def cocomap(data, batch_size = 512):\n","  #Reduce 19 to 14 joints\n","  joint = np.zeros((batch_size, 14,3))\n","  total = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n","  count = 0\n","  for i in total:\n","    joint[:,count] = data[:,i]\n","    count += 1\n","  return joint\n","\n","def gtmap(data, batch_size=512):\n","  #Reduce 17 to 14 joints\n","  joint = np.zeros((batch_size, 14,3))\n","  total = [3,2,1,4,5,6, 16,15,14,11,12,13,9,10]\n","  count = 0\n","  for i in total:\n","    joint[:, count] = data[:, i]\n","    count += 1\n","  return joint\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mv7w0FV68OYP"},"source":["def loss_3d(kp3d_sym, gt3d):\n","    kp3d_mpjpe_aligned = tf.norm(kp3d_sym - gt3d, axis=2)\n","    kp3d_mpjpe_aligned = tf.reduce_mean(kp3d_mpjpe_aligned)\n","    return kp3d_mpjpe_aligned"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AZRvuM_a1p_B"},"source":["def loss_compute(pred, central, gt3d):\n","    pred = pred.cpu()\n","    central = central.cpu()\n","    loss1 = torch.mean(torch.norm((pred.squeeze() - central.squeeze()), dim = 1))\n","\n","    pred = np.squeeze(pred)\n","    gt3d = np.squeeze(gt3d)\n","    \n","    pred = pred.detach().numpy()\n","    pred = tf.convert_to_tensor(pred)\n","    vertices, kp3d_pred, shapes = smpl2vertices(pred)\n","\n","    joint_3d = cocomap(kp3d_pred)\n","    # print(joint_3d.shape)\n","\n","    gt_3d = gt3d.detach().numpy()\n","    # print(gt_3d.shape)\n","    joint_gt_3d = gtmap(gt_3d)\n","\n","    # print(joint_gt_3d.shape)\n","    gt3d = batch_align_by_pelvis(joint_gt_3d)\n","    kp3d = batch_align_by_pelvis(joint_3d)\n","    # kp3d = torch.from_numpy(kp3d)\n","    # gt3d = torch.from_numpy(gt3d)\n","    kp3d = tf.cast(kp3d, float)\n","    gt3d = tf.cast(gt3d, float)\n","\n","    kp3d_sym = batch_compute_similarity_transform(gt3d, kp3d)\n","\n","    loss2 = loss_3d(kp3d_sym, gt3d)\n","    loss2 = loss2.numpy()\n","    loss2 = torch.from_numpy(np.asarray(loss2))\n","\n","    loss = loss1 + 10 * loss2\n","    # print(\" The total loss is: \", loss, '\\n', 'The smpl loss is: ', loss1, '\\n', 'The 3D joints loss is: ', loss2)\n","\n","    return loss, loss1, loss2\n","\n","# loss_compute(central, central, gt_3d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0PKV36cnDkBZ"},"source":["def loss_compute_growth(pred, central, gt3d, epoch):\n","    pred = pred.cpu()\n","    central = central.cpu()\n","    loss1 = torch.mean(torch.norm((pred.squeeze() - central.squeeze()), dim = 1))\n","\n","    pred = np.squeeze(pred)\n","    gt3d = np.squeeze(gt3d)\n","    \n","    pred = pred.detach().numpy()\n","    pred = tf.convert_to_tensor(pred)\n","    vertices, kp3d_pred, shapes = smpl2vertices(pred)\n","\n","    joint_3d = cocomap(kp3d_pred)\n","    # print(joint_3d.shape)\n","\n","    gt_3d = gt3d.detach().numpy()\n","    # print(gt_3d.shape)\n","    joint_gt_3d = gtmap(gt_3d)\n","\n","    # print(joint_gt_3d.shape)\n","    gt3d = batch_align_by_pelvis(joint_gt_3d)\n","    kp3d = batch_align_by_pelvis(joint_3d)\n","    # kp3d = torch.from_numpy(kp3d)\n","    # gt3d = torch.from_numpy(gt3d)\n","    kp3d = tf.cast(kp3d, float)\n","    gt3d = tf.cast(gt3d, float)\n","\n","    kp3d_sym = batch_compute_similarity_transform(gt3d, kp3d)\n","\n","    loss2 = loss_3d(kp3d_sym, gt3d)\n","    loss2 = loss2.numpy()\n","    loss2 = torch.from_numpy(np.asarray(loss2))\n","\n","    k = 1+epoch*0.1\n","\n","    loss = 100*loss1 + 1000 * k * loss2\n","    # print(\" The total loss is: \", loss, '\\n', 'The smpl loss is: ', loss1, '\\n', 'The 3D joints loss is: ', loss2)\n","\n","    return loss, 100*loss1, 1000*loss2\n","\n","# loss_compute(central, central, gt_3d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-MKOh3eApquQ"},"source":["def loss_compute_grad(pred, central, gt3d, epoch):\n","    pred = pred.cpu()\n","    central = central.cpu()\n","    loss1 = torch.mean(torch.norm((pred.squeeze() - central.squeeze()), dim = 1))\n","\n","    pred = np.squeeze(pred)\n","    gt3d = np.squeeze(gt3d)\n","    \n","    pred = pred.detach().numpy()\n","    pred = tf.convert_to_tensor(pred)\n","    vertices, kp3d_pred, shapes = smpl2vertices(pred)\n","\n","    joint_3d = cocomap(kp3d_pred)\n","    # print(joint_3d.shape)\n","\n","    gt_3d = gt3d.detach().numpy()\n","    # print(gt_3d.shape)\n","    joint_gt_3d = gtmap(gt_3d)\n","\n","    # print(joint_gt_3d.shape)\n","    gt3d = batch_align_by_pelvis(joint_gt_3d)\n","    kp3d = batch_align_by_pelvis(joint_3d)\n","    # kp3d = torch.from_numpy(kp3d)\n","    # gt3d = torch.from_numpy(gt3d)\n","    kp3d = tf.cast(kp3d, float)\n","    gt3d = tf.cast(gt3d, float)\n","\n","    kp3d_sym = batch_compute_similarity_transform(gt3d, kp3d)\n","\n","    loss2 = loss_3d(kp3d_sym, gt3d)\n","    loss2 = loss2.numpy()\n","    loss2 = torch.from_numpy(np.asarray(loss2))\n","\n","    k = 1+epoch*0.1\n","\n","    loss = loss1*loss2*1000\n","    # print(\" The total loss is: \", loss, '\\n', 'The smpl loss is: ', loss1, '\\n', 'The 3D joints loss is: ', loss2)\n","\n","    return loss, loss1, 1000*loss2\n","\n","# loss_compute(central, central, gt_3d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qSuKRzHWEbnc"},"source":["def mpjpe(pred, central, gt3d):\n","    pred = pred.cpu()\n","    central = central.cpu()\n","    loss1 = torch.mean(torch.norm((pred.squeeze() - central.squeeze()), dim = 1))\n","\n","    pred = np.squeeze(pred)\n","    gt3d = np.squeeze(gt3d)\n","    \n","    pred = pred.detach().numpy()\n","    pred = tf.convert_to_tensor(pred)\n","    vertices, kp3d_pred, shapes = smpl2vertices(pred)\n","\n","    joint_3d = cocomap(kp3d_pred)\n","    # print(joint_3d.shape)\n","\n","    gt_3d = gt3d.detach().numpy()\n","    # print(gt_3d.shape)\n","    joint_gt_3d = gtmap(gt_3d)\n","\n","    # print(joint_gt_3d.shape)\n","    gt3d = batch_align_by_pelvis(joint_gt_3d)\n","    kp3d = batch_align_by_pelvis(joint_3d)\n","    # kp3d = torch.from_numpy(kp3d)\n","    # gt3d = torch.from_numpy(gt3d)\n","    kp3d = tf.cast(kp3d, float)\n","    gt3d = tf.cast(gt3d, float)\n","\n","    kp3d_sym = batch_compute_similarity_transform(gt3d, kp3d)\n","\n","    loss2 = loss_3d(kp3d_sym, gt3d)\n","    loss2 = loss2.numpy()\n","    loss2 = torch.from_numpy(np.asarray(loss2))\n","\n","\n","    k1 = 1\n","    k2 = 1+epoch*0.1\n","    k1 = k1/(k1+k2)\n","    k2 = k2/(k1+k2)\n","\n","    loss = k1* 100 * loss1 + 1000 * k2 * loss2\n","    # print(\" The total loss is: \", loss, '\\n', 'The smpl loss is: ', loss1, '\\n', 'The 3D joints loss is: ', loss2)\n","\n","    return loss2*1000\n","\n","# loss_compute(central, central, gt_3d)"],"execution_count":null,"outputs":[]}]}