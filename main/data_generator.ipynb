{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"data_generator.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"JzJNLMAK5USo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638672013450,"user_tz":420,"elapsed":16248,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"}},"outputId":"2803c025-c8e7-499f-d80c-cb52f9a27df7"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GqCsGKGk4YY1","executionInfo":{"status":"ok","timestamp":1638672013918,"user_tz":420,"elapsed":4,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"}},"outputId":"dd39084e-96cf-42b7-cdac-cba4943de19d"},"source":["%cd /content/drive/MyDrive/HME/Temporal-Transformer"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/HME/Temporal-Transformer\n"]}]},{"cell_type":"code","metadata":{"id":"7-YOVqAJIRau"},"source":["from itertools import zip_longest\n","import numpy as np\n","import random\n","import torch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9nrZmzYS48OY"},"source":["def get_frame_num(frame_name):\n","    l = frame_name.split('_')\n","\n","    m = l[1].split('.')\n","    n = m[0]\n","    frame_num = int(n)\n","    return frame_num"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z168MXRo5Ow5"},"source":["# print(get_frame_num('frame_201.jpg'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"scSEsR1ERh3b"},"source":["def get_j_neighbor(dataset, central_idx, one_side, j, S, video, central_frame_num):\n","    # subject = []\n","    if dataset[central_idx + j][0][0] == S:\n","        if dataset[central_idx - 1][0][1] == video:\n","\n","            # extract the frame number\n","            frame_name = dataset[central_idx + j][0][2]\n","            frame_num = get_frame_num(frame_name)\n","            if frame_num == central_frame_num + 20*j:\n","\n","                ##########################\n","                '''change here to revise the input data'''\n","                # make pose for an example\n","                subject = dataset[central_idx + j][3]\n","            else:\n","                subject = dataset[central_idx][3]\n","                print('the ', j,  'of frame', central_frame_num, 'not found')\n","        \n","        else:\n","            subject = dataset[central_idx][3]\n","            print('the ', j,  'of frame ', central_frame_num, 'not found')\n","    else:\n","        subject = dataset[central_idx][3]\n","        print('the ', j,  'of frame ', central_frame_num, 'not found')\n","    return subject"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tuuxeb3fcLcq"},"source":["def get_j_neighbor_without_print(dataset, central_idx, one_side, j, S, video, central_frame_num):\n","    # subject = []\n","    if dataset[central_idx + j][0][0] == S:\n","        if dataset[central_idx - 1][0][1] == video:\n","\n","            # extract the frame number\n","            frame_name = dataset[central_idx + j][0][2]\n","            frame_num = get_frame_num(frame_name)\n","            if frame_num == central_frame_num + 20*j:\n","\n","                ##########################\n","                '''change here to revise the input data'''\n","                # make pose for an example\n","                subject = dataset[central_idx + j][3]\n","            else:\n","                subject = dataset[central_idx][3]\n","                # print('the ', j,  'of frame', central_frame_num, 'not found')\n","        \n","        else:\n","            subject = dataset[central_idx][3]\n","            # print('the ', j,  'of frame ', central_frame_num, 'not found')\n","    else:\n","        subject = dataset[central_idx][3]\n","        # print('the ', j,  'of frame ', central_frame_num, 'not found')\n","    return subject"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zg1vkDxAJM7n"},"source":["def get_j_neighbor_with_index(dataset, central_idx, one_side, j, S, video, central_frame_num, type=3):\n","    # subject = []\n","    if dataset[central_idx + j][0][0] == S:\n","        if dataset[central_idx - 1][0][1] == video:\n","\n","            # extract the frame number\n","            frame_name = dataset[central_idx + j][0][2]\n","            frame_num = get_frame_num(frame_name)\n","            if frame_num == central_frame_num + 20*j:\n","\n","                ##########################\n","                '''change here to revise the input data'''\n","                # make pose for an example\n","                subject = dataset[central_idx + j][type]\n","            else:\n","                subject = dataset[central_idx][type]\n","                # print('the ', j,  'of frame', central_frame_num, 'not found')\n","        \n","        else:\n","            subject = dataset[central_idx][type]\n","            # print('the ', j,  'of frame ', central_frame_num, 'not found')\n","    else:\n","        subject = dataset[central_idx][type]\n","        # print('the ', j,  'of frame ', central_frame_num, 'not found')\n","    return subject"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OENLaC6ibHmS"},"source":["class Dataloader_zzx:\n","    def __init__(self, dataset, batch_size=512, receptive_field=9):\n","        # dataset = np.transpose(dataset, (1,0))    # not needed for the newly formed trainingdata\n","        self.tol_num_data = len(dataset)\n","        self.batch_size = batch_size\n","        self.n_batches = self.tol_num_data // self.batch_size\n","        self.receptive_field = receptive_field\n","        self.dataset = dataset\n","        self.one_side = receptive_field // 2      # how many frames to search in one side\n","    \n","    def generator(self):\n","        print(\"dividing data......\")\n","        for i in range(self.n_batches):\n","            # local batch and labels\n","            indices = random.sample(range(0,self.tol_num_data), self.batch_size)\n","            central_images = self.dataset[indices]      # retrieve data by raws\n","            one_side = self.one_side\n","\n","            current_batch = []\n","            subject = []\n","            # generate the data from an single frame and combine them together.\n","            for i, img in enumerate(central_images):\n","\n","                S, video, frame = img[0]        # Ex: S = 'S1', video = 'Posing 1.54138969', frame = 'frame_201.jpg'\n","                central_frame_num = get_frame_num(frame)\n","                # get the location of the central frame in the dataset.\n","                central_idx = indices[i]\n","\n","                # repeat the central frame if can't find the neighbor frames.\n","                if central_idx <= self.one_side or central_idx >= self.tol_num_data - self.one_side:\n","                    '''change here'''\n","                    subject_central = img[3]\n","                    subject = [subject_central] * self.one_side * 2   # repeat the element for 2*one_side times.\n","                    # print('******************', len(subject))\n","                    subject_np = subject[0]\n","                    # print(len(subject), '\\n', central_frame_num)\n","                    for frame_np in subject[1:]:\n","                        subject_np = np.vstack([subject_np, frame_np])\n","                    \n","                    current_batch.append(subject_np)\n","\n","                    subject = [] #set subject clear\n","                    \n","                    # print('get neighbors for', central_frame_num,'\\n', '####################')\n","\n","                    continue\n","                    # break\n","                \n","                # generate the sequence list: the left and right of the central frame\n","                else:\n","                    for j in [x for x in range(-self.one_side, 0)] + [x+1 for x in range(0, self.one_side)]:    # without the central frame\n","                        subject.append(get_j_neighbor_with_index(self.dataset, central_idx, self.one_side, j, S, video, central_frame_num))\n","\n","                \n","\n","                # convert the list (len(6)) to array that is (6*)   (85)*9 -> (9,85)\n","                # stack list elements as row in numpy.array\n","                subject_np = subject[0]\n","                # print(len(subject), '\\n', central_frame_num)\n","                for frame_np in subject[1:]:\n","                    subject_np = np.vstack([subject_np, frame_np])\n","                \n","                current_batch.append(subject_np)\n","\n","                subject = [] #set subject clear\n","                \n","\n","\n","\n","            ######## pose_and_shape ##########\n","            # convert the list to numpy (9,85) -> (512,9,85)\n","            batch_np = current_batch[0]\n","            batch_np = np.expand_dims(batch_np, axis=0)\n","            for bundle in current_batch[1:]:\n","                bundle = np.expand_dims(bundle, axis=0)\n","                batch_np = np.vstack([batch_np, bundle])\n","\n","\n","\n","\n","\n","            # numpy -> tensor\n","            training_set_batch = torch.from_numpy(batch_np)\n","            central_gt_batch = torch.from_numpy(central_gt_np)\n","            yield training_set_batch      # yield the result\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gcanbhifbXV_"},"source":["class Dataloader_zzx_video:\n","    def __init__(self, video_path, receptive_field=9):\n","        # dataset = np.transpose(dataset, (1,0))    # not needed for the newly formed trainingdata\n","        \n","        # data =[]\n","        # for filename in os.listdir(dataset_folder):\n","        #     file_path = os.path.join(folder_name, filename)\n","        #     data.append(np.load(file_path, allow_pickle=True).transpose(1,0))\n","        \n","        # dataset = data[0]\n","        # for i in data[1:]:\n","        #     dataset = np.vstack([dataset, i])   \n","        dataset = np.load(video_path, allow_pickle=True).transpose(1,0)\n","        print(len(dataset))\n","\n","        self.tol_num_data = len(dataset)\n","        self.receptive_field = receptive_field\n","        self.dataset = dataset\n","        self.one_side = receptive_field // 2      # how many frames to search in one side\n","    \n","    def generator(self):\n","        print(\"dividing data......\")\n","        # local batch and labels\n","        indices = [x for x in range(self.tol_num_data)]\n","        # central_images = self.dataset[indices]      # retrieve data by raws\n","        one_side = self.one_side\n","\n","\n","\n","        current_batch = []\n","        subject = []\n","        central_gt = []\n","        central_name = []\n","        # generate the data from an single frame and combine them together.\n","        for i, img in enumerate(self.dataset):\n","\n","            # import pdb\n","            # pdb.set_trace()\n","            central_gt.append(np.expand_dims(img[3], axis=0))\n","            central_name.append(np.expand_dims(img[0], axis=0))\n","\n","\n","            S, video, frame = img[0]        # Ex: S = 'S1', video = 'Posing 1.54138969', frame = 'frame_201.jpg'\n","            central_frame_num = get_frame_num(frame)\n","            # get the location of the central frame in the dataset.\n","            central_idx = indices[i]\n","\n","            # repeat the central frame if can't find the neighbor frames.\n","            if central_idx <= self.one_side or central_idx >= self.tol_num_data - self.one_side:\n","                '''change here'''\n","                subject_central = img[3]\n","                subject = [subject_central] * self.one_side * 2   # repeat the element for 2*one_side times.\n","                \n","                subject_np = subject[0]\n","                for frame_np in subject[1:]:\n","                    subject_np = np.vstack([subject_np, frame_np])\n","                \n","                current_batch.append(subject_np)\n","\n","                subject = [] #set subject clear\n","                \n","                \n","\n","                continue\n","              \n","            \n","            # generate the sequence list: the left and right of the central frame\n","            else:\n","                for j in [x for x in range(-self.one_side, 0)] + [x+1 for x in range(0, self.one_side)]:    # without the central frame\n","                    subject.append(get_j_neighbor_without_print(self.dataset, central_idx, self.one_side, j, S, video, central_frame_num))\n","        \n","            subject_np = subject[0]\n","\n","            for frame_np in subject[1:]:\n","                subject_np = np.vstack([subject_np, frame_np])\n","            \n","            current_batch.append(subject_np)\n","\n","            subject = [] #set subject clear\n","                \n","\n","\n","\n","        ######## pose_and_shape ##########\n","        # convert the list to numpy (9,85) -> (512,9,85)\n","        batch_np = current_batch[0]\n","        batch_np = np.expand_dims(batch_np, axis=0)\n","        for bundle in current_batch[1:]:\n","            bundle = np.expand_dims(bundle, axis=0)\n","            batch_np = np.vstack([batch_np, bundle])\n","        # numpy -> tensor\n","        training_set_batch = torch.from_numpy(batch_np)\n","\n","        ######## central GT ###########\n","        central_gt_np = central_gt[0]\n","        central_gt_np = np.expand_dims(central_gt_np, axis = 0)\n","        for central in central_gt[1:]:\n","            central = np.expand_dims(central, axis=0)\n","            central_gt_np = np.vstack([central_gt_np, central])\n","        # numpy -> tensor\n","        central_gt_batch = torch.from_numpy(central_gt_np)\n","\n","\n","\n","        ####### central name #########\n","        yield training_set_batch, central_gt_batch, central_name      # yield the result\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"sj0E0SpXdat_","executionInfo":{"status":"error","timestamp":1638683341704,"user_tz":420,"elapsed":16,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"}},"outputId":"bbc01489-e854-481e-c286-f3a3e14e0167"},"source":["### specific video experiment\n","import os\n","\n","hm_path = '/content/drive/MyDrive/HME/H36M Data/Cropped Images/HMR Outputs/Structure 2_gt'\n","\n","subject = 'S6'\n","video_name = 'Discussion 1.54138969' + '_resultsgt.npy'\n","# Directions 1.58860488_resultsgt.npy\n","# Discussion 1.54138969, Greeting 1.58860488, \\Sitting 1.58860488\n","\n","subject_folder = os.path.join(hm_path, subject)\n","video_path = os.path.join(subject_folder, video_name)\n","\n","dataloader = Dataloader_zzx_video(video_path, receptive_field=9)\n","\n","for i, central_i, central_name in dataloader.generator():\n","    print(central_name\n",")"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-6496afc8991d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mvideo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataloader_zzx_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreceptive_field\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentral_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentral_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Dataloader_zzx_video' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EF_aM7fNyhNE","executionInfo":{"status":"ok","timestamp":1638677619956,"user_tz":420,"elapsed":164,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"}},"outputId":"dd7124bf-059d-44ba-b276-f284a35858b1"},"source":["a = np.ones((10,1))\n","b = np.linspace(0,5,10)\n","indices = random.sample(range(0,10), 3)\n","print(indices)\n","\n","c = [x for x in range(10)]\n","print(c)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[5, 0, 7]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"]}]},{"cell_type":"code","metadata":{"id":"fPnWcOO3UE71"},"source":["class Dataloader_zzx_central_gt_frame:\n","    def __init__(self, dataset, batch_size=512, receptive_field=9):\n","        # dataset = np.transpose(dataset, (1,0))    # not needed for the newly formed trainingdata\n","        self.tol_num_data = len(dataset)\n","        self.batch_size = batch_size\n","        self.n_batches = self.tol_num_data // self.batch_size\n","        self.receptive_field = receptive_field\n","        self.dataset = dataset\n","        self.one_side = receptive_field // 2      # how many frames to search in one side\n","    \n","    def generator(self):\n","        print(\"dividing data......\")\n","        for i in range(self.n_batches):\n","            # local batch and labels\n","            indices = random.sample(range(0,self.tol_num_data), self.batch_size)\n","            central_images = self.dataset[indices]      # retrieve data by raws\n","            one_side = self.one_side\n","\n","            current_batch = []\n","            subject = []\n","            central_gt = []\n","            central_name = []\n","            # generate the data from an single frame and combine them together.\n","            for i, img in enumerate(central_images):\n","\n","                # import pdb\n","                # pdb.set_trace()\n","                central_gt.append(np.expand_dims(img[3], axis=0))\n","                central_name.append(np.expand_dims(img[0], axis=0))\n","\n","\n","                S, video, frame = img[0]        # Ex: S = 'S1', video = 'Posing 1.54138969', frame = 'frame_201.jpg'\n","                central_frame_num = get_frame_num(frame)\n","                # get the location of the central frame in the dataset.\n","                central_idx = indices[i]\n","\n","                # repeat the central frame if can't find the neighbor frames.\n","                if central_idx <= self.one_side or central_idx >= self.tol_num_data - self.one_side:\n","                    '''change here'''\n","                    subject_central = img[3]\n","                    subject = [subject_central] * self.one_side * 2   # repeat the element for 2*one_side times.\n","                    \n","                    subject_np = subject[0]\n","                    for frame_np in subject[1:]:\n","                        subject_np = np.vstack([subject_np, frame_np])\n","                    \n","                    current_batch.append(subject_np)\n","\n","                    subject = [] #set subject clear\n","                    \n","                   \n","\n","                    continue\n","                  \n","                \n","                # generate the sequence list: the left and right of the central frame\n","                else:\n","                    for j in [x for x in range(-self.one_side, 0)] + [x+1 for x in range(0, self.one_side)]:    # without the central frame\n","                        subject.append(get_j_neighbor_without_print(self.dataset, central_idx, self.one_side, j, S, video, central_frame_num))\n","           \n","                subject_np = subject[0]\n","\n","                for frame_np in subject[1:]:\n","                    subject_np = np.vstack([subject_np, frame_np])\n","                \n","                current_batch.append(subject_np)\n","\n","                subject = [] #set subject clear\n","                \n","\n","\n","\n","            ######## pose_and_shape ##########\n","            # convert the list to numpy (9,85) -> (512,9,85)\n","            batch_np = current_batch[0]\n","            batch_np = np.expand_dims(batch_np, axis=0)\n","            for bundle in current_batch[1:]:\n","                bundle = np.expand_dims(bundle, axis=0)\n","                batch_np = np.vstack([batch_np, bundle])\n","            # numpy -> tensor\n","            training_set_batch = torch.from_numpy(batch_np)\n","\n","            ######## central GT ###########\n","            central_gt_np = central_gt[0]\n","            central_gt_np = np.expand_dims(central_gt_np, axis = 0)\n","            for central in central_gt[1:]:\n","                central = np.expand_dims(central, axis=0)\n","                central_gt_np = np.vstack([central_gt_np, central])\n","            # numpy -> tensor\n","            central_gt_batch = torch.from_numpy(central_gt_np)\n","\n","\n","\n","            ####### central name #########\n","            yield training_set_batch, central_gt_batch, central_name      # yield the result\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rRMMOtktBTFb"},"source":["class Dataloader_zzx_central_gt:\n","    def __init__(self, dataset, batch_size=512, receptive_field=9):\n","        # dataset = np.transpose(dataset, (1,0))    # not needed for the newly formed trainingdata\n","        self.tol_num_data = len(dataset)\n","        self.batch_size = batch_size\n","        self.n_batches = self.tol_num_data // self.batch_size\n","        self.receptive_field = receptive_field\n","        self.dataset = dataset\n","        self.one_side = receptive_field // 2      # how many frames to search in one side\n","    \n","    def generator(self):\n","        print(\"dividing data......\")\n","        for i in range(self.n_batches):\n","            # local batch and labels\n","            indices = random.sample(range(0,self.tol_num_data), self.batch_size)\n","            central_images = self.dataset[indices]      # retrieve data by raws\n","            one_side = self.one_side\n","\n","            current_batch = []\n","            subject = []\n","            central_gt = []\n","            # generate the data from an single frame and combine them together.\n","            for i, img in enumerate(central_images):\n","\n","                # import pdb\n","                # pdb.set_trace()\n","                central_gt.append(np.expand_dims(img[3], axis=0))\n","\n","\n","\n","                S, video, frame = img[0]        # Ex: S = 'S1', video = 'Posing 1.54138969', frame = 'frame_201.jpg'\n","                central_frame_num = get_frame_num(frame)\n","                # get the location of the central frame in the dataset.\n","                central_idx = indices[i]\n","\n","                # repeat the central frame if can't find the neighbor frames.\n","                if central_idx <= self.one_side or central_idx >= self.tol_num_data - self.one_side:\n","                    '''change here'''\n","                    subject_central = img[3]\n","                    subject = [subject_central] * self.one_side * 2   # repeat the element for 2*one_side times.\n","                    \n","                    subject_np = subject[0]\n","                    for frame_np in subject[1:]:\n","                        subject_np = np.vstack([subject_np, frame_np])\n","                    \n","                    current_batch.append(subject_np)\n","\n","                    subject = [] #set subject clear\n","                    \n","                   \n","\n","                    continue\n","                  \n","                \n","                # generate the sequence list: the left and right of the central frame\n","                else:\n","                    for j in [x for x in range(-self.one_side, 0)] + [x+1 for x in range(0, self.one_side)]:    # without the central frame\n","                        subject.append(get_j_neighbor_without_print(self.dataset, central_idx, self.one_side, j, S, video, central_frame_num))\n","           \n","                subject_np = subject[0]\n","\n","                for frame_np in subject[1:]:\n","                    subject_np = np.vstack([subject_np, frame_np])\n","                \n","                current_batch.append(subject_np)\n","\n","                subject = [] #set subject clear\n","                \n","\n","\n","\n","            ######## pose_and_shape ##########\n","            # convert the list to numpy (9,85) -> (512,9,85)\n","            batch_np = current_batch[0]\n","            batch_np = np.expand_dims(batch_np, axis=0)\n","            for bundle in current_batch[1:]:\n","                bundle = np.expand_dims(bundle, axis=0)\n","                batch_np = np.vstack([batch_np, bundle])\n","            # numpy -> tensor\n","            training_set_batch = torch.from_numpy(batch_np)\n","\n","            ######## central GT ###########\n","            central_gt_np = central_gt[0]\n","            central_gt_np = np.expand_dims(central_gt_np, axis = 0)\n","            for central in central_gt[1:]:\n","                central = np.expand_dims(central, axis=0)\n","                central_gt_np = np.vstack([central_gt_np, central])\n","            # numpy -> tensor\n","            central_gt_batch = torch.from_numpy(central_gt_np)\n","            yield training_set_batch, central_gt_batch      # yield the result\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kuAbd3z7Dfmf"},"source":["class Dataloader_zzx_central_hm36_gt_tag:\n","    def __init__(self, dataset, batch_size=512, receptive_field=9):\n","        # dataset = np.transpose(dataset, (1,0))    # not needed for the newly formed trainingdata\n","        self.tol_num_data = len(dataset)\n","        self.batch_size = batch_size\n","        self.n_batches = self.tol_num_data // self.batch_size\n","        self.receptive_field = receptive_field\n","        self.dataset = dataset\n","        self.one_side = receptive_field // 2      # how many frames to search in one side\n","    \n","    def generator(self):\n","        print(\"dividing data......\")\n","        for i in range(self.n_batches):\n","            # local batch and labels\n","            indices = random.sample(range(0,self.tol_num_data), self.batch_size)\n","            central_images = self.dataset[indices]      # retrieve data by raws\n","            one_side = self.one_side\n","\n","            current_batch = []\n","            subject = []\n","            central_gt = []\n","            central_3d_gt = []\n","            central_cams = []\n","            central_name = []\n","            # generate the data from an single frame and combine them together.\n","            for i, img in enumerate(central_images):\n","\n","                # import pdb\n","                # pdb.set_trace()\n","                central_gt.append(np.expand_dims(img[3], axis=0))\n","                central_3d_gt.append(np.expand_dims(img[6], axis = 0))\n","                central_cams.append(np.expand_dims(img[4],axis=0))\n","                central_name.append(np.expand_dims(img[0], axis=0))\n","\n","                S, video, frame = img[0]        # Ex: S = 'S1', video = 'Posing 1.54138969', frame = 'frame_201.jpg'\n","                central_frame_num = get_frame_num(frame)\n","                # get the location of the central frame in the dataset.\n","                central_idx = indices[i]\n","\n","                # repeat the central frame if can't find the neighbor frames.\n","                if central_idx <= self.one_side or central_idx >= self.tol_num_data - self.one_side:\n","                    '''change here'''\n","                    subject_central = img[3]\n","                    subject = [subject_central] * self.one_side * 2   # repeat the element for 2*one_side times.\n","                    \n","                    subject_np = subject[0]\n","                    for frame_np in subject[1:]:\n","                        subject_np = np.vstack([subject_np, frame_np])\n","                    \n","                    current_batch.append(subject_np)\n","\n","                    subject = [] #set subject clear\n","                    \n","                   \n","\n","                    continue\n","                  \n","                \n","                # generate the sequence list: the left and right of the central frame\n","                else:\n","                    for j in [x for x in range(-self.one_side, 0)] + [x+1 for x in range(0, self.one_side)]:    # without the central frame\n","                        subject.append(get_j_neighbor_without_print(self.dataset, central_idx, self.one_side, j, S, video, central_frame_num))\n","           \n","                subject_np = subject[0]\n","\n","                for frame_np in subject[1:]:\n","                    subject_np = np.vstack([subject_np, frame_np])\n","                \n","                current_batch.append(subject_np)\n","\n","                subject = [] #set subject clear\n","                \n","\n","\n","\n","            ######## pose_and_shape ##########\n","            # convert the list to numpy (9,85) -> (512,9,85)\n","            batch_np = current_batch[0]\n","            batch_np = np.expand_dims(batch_np, axis=0)\n","            for bundle in current_batch[1:]:\n","                bundle = np.expand_dims(bundle, axis=0)\n","                batch_np = np.vstack([batch_np, bundle])\n","            # numpy -> tensor\n","            training_set_batch = torch.from_numpy(batch_np)\n","\n","            ######## central GT ###########\n","            central_gt_np = central_gt[0]\n","            central_gt_np = np.expand_dims(central_gt_np, axis = 0)\n","            for central in central_gt[1:]:\n","                central = np.expand_dims(central, axis=0)\n","                central_gt_np = np.vstack([central_gt_np, central])\n","            # numpy -> tensor\n","            central_gt_batch = torch.from_numpy(central_gt_np)\n","\n","            ####### central 3d GT#########\n","            central_3d_gt_np = central_3d_gt[0]\n","            central_3d_gt_np = np.expand_dims(central_3d_gt_np, axis = 0)  \n","            for central_3d in central_3d_gt[1:]:\n","                central_3d = np.expand_dims(central_3d, axis=0)\n","                central_3d_gt_np = np.vstack([central_3d_gt_np, central_3d])\n","            central_3d_gt_batch = torch.from_numpy(central_3d_gt_np)\n","\n","\n","            ####### cams ###########\n","            cams_np = central_cams[0]\n","            cams_np = np.expand_dims(cams_np, axis = 0)\n","            for cam in central_cams[1:]:\n","                cam = np.expand_dims(cam, axis=0)\n","                cams_np = np.vstack([cams_np, cam])\n","            cams_batch = torch.from_numpy(cams_np)\n","\n","            yield training_set_batch, central_gt_batch, central_3d_gt_batch, cams_batch, central_name      # yield the result\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iZSBt7t64I8f","colab":{"base_uri":"https://localhost:8080/","height":351},"executionInfo":{"status":"error","timestamp":1638741196124,"user_tz":420,"elapsed":753,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"}},"outputId":"2199e46b-d6aa-4ef8-ee05-1f0086ba3dd8"},"source":["import numpy as np\n","data = np.load('trainingdata.npy', allow_pickle=True)\n","dataloader = Dataloader_zzx_central_hm36_gt_tag(data, batch_size=512)\n","for i, central, central_3d, cams, names in dataloader.generator():\n","    print(cams.shape)     # expected\n","    break\n","\n","# central.squeeze().shape"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-06177a6198c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trainingdata.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataloader_zzx_central_hm36_gt_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentral\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentral_3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'trainingdata.npy'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kBQuIt7-UtVH","executionInfo":{"status":"ok","timestamp":1638652979815,"user_tz":420,"elapsed":1679,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"}},"outputId":"3c2827a2-1ba9-4717-f543-4ecac0c1095b"},"source":["import numpy as np\n","data = np.load('trainingdata.npy', allow_pickle=True)\n","dataloader = Dataloader_zzx_central_gt_frame(data, batch_size=512)\n","for i, central, name in dataloader.generator():\n","    print(name)     # expected\n","    break\n","\n","# central.squeeze().shape"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dividing data......\n","[array([['S11', 'Posing.54138969', 'frame_721.jpg']], dtype='<U15'), array([['S11', 'Posing.54138969', 'frame_561.jpg']], dtype='<U15'), array([['S9', 'Waiting 1.55011271', 'frame_221.jpg']], dtype='<U18'), array([['S7', 'WalkTogether 1.55011271', 'frame_1541.jpg']], dtype='<U23'), array([['S7', 'SittingDown 1.54138969', 'frame_2621.jpg']], dtype='<U22'), array([['S9', 'SittingDown.60457274', 'frame_1741.jpg']], dtype='<U20'), array([['S9', 'Greeting 1.54138969', 'frame_1601.jpg']], dtype='<U19'), array([['S5', 'WalkDog.54138969', 'frame_1961.jpg']], dtype='<U16'), array([['S1', 'WalkingDog 1.58860488', 'frame_61.jpg']], dtype='<U21'), array([['S9', 'WalkDog.60457274', 'frame_201.jpg']], dtype='<U16'), array([['S11', 'Smoking 2.54138969', 'frame_1561.jpg']], dtype='<U18'), array([['S5', 'Eating 1.54138969', 'frame_221.jpg']], dtype='<U17'), array([['S1', 'Greeting.60457274', 'frame_41.jpg']], dtype='<U17'), array([['S1', 'WalkingDog.58860488', 'frame_741.jpg']], dtype='<U19'), array([['S7', 'Sitting 1.54138969', 'frame_1701.jpg']], dtype='<U18'), array([['S7', 'Waiting 2.60457274', 'frame_1981.jpg']], dtype='<U18'), array([['S1', 'WalkTogether 1.55011271', 'frame_821.jpg']], dtype='<U23'), array([['S1', 'TakingPhoto.55011271', 'frame_941.jpg']], dtype='<U20'), array([['S5', 'WalkDog.60457274', 'frame_261.jpg']], dtype='<U16'), array([['S5', 'Directions 1.58860488', 'frame_481.jpg']], dtype='<U21'), array([['S9', 'WalkTogether 1.60457274', 'frame_481.jpg']], dtype='<U23'), array([['S1', 'Eating.54138969', 'frame_1821.jpg']], dtype='<U15'), array([['S5', 'Sitting 1.60457274', 'frame_2881.jpg']], dtype='<U18'), array([['S5', 'WalkTogether.60457274', 'frame_581.jpg']], dtype='<U21'), array([['S11', 'Photo 1.54138969', 'frame_801.jpg']], dtype='<U16'), array([['S5', 'Discussion 2.55011271', 'frame_5161.jpg']], dtype='<U21'), array([['S5', 'Waiting 1.60457274', 'frame_1621.jpg']], dtype='<U18'), array([['S7', 'Smoking.58860488', 'frame_2241.jpg']], dtype='<U16'), array([['S9', 'Purchases.60457274', 'frame_1101.jpg']], dtype='<U18'), array([['S5', 'Smoking 1.58860488', 'frame_741.jpg']], dtype='<U18'), array([['S11', 'Photo.54138969', 'frame_901.jpg']], dtype='<U14'), array([['S9', 'Greeting.54138969', 'frame_1181.jpg']], dtype='<U17'), array([['S9', 'Photo 1.54138969', 'frame_681.jpg']], dtype='<U16'), array([['S11', 'WalkTogether.58860488', 'frame_501.jpg']], dtype='<U21'), array([['S9', 'Smoking 1.55011271', 'frame_441.jpg']], dtype='<U18'), array([['S5', 'Discussion 2.58860488', 'frame_4661.jpg']], dtype='<U21'), array([['S1', 'Discussion.54138969', 'frame_801.jpg']], dtype='<U19'), array([['S11', 'Smoking 2.60457274', 'frame_1341.jpg']], dtype='<U18'), array([['S11', 'Phoning 2.54138969', 'frame_641.jpg']], dtype='<U18'), array([['S1', 'WalkingDog 1.58860488', 'frame_461.jpg']], dtype='<U21'), array([['S11', 'Eating.55011271', 'frame_841.jpg']], dtype='<U15'), array([['S5', 'Eating.60457274', 'frame_961.jpg']], dtype='<U15'), array([['S5', 'Greeting 2.58860488', 'frame_2621.jpg']], dtype='<U19'), array([['S11', 'WalkTogether 1.54138969', 'frame_1101.jpg']], dtype='<U23'), array([['S7', 'Posing.60457274', 'frame_1801.jpg']], dtype='<U15'), array([['S11', 'Phoning 2.54138969', 'frame_161.jpg']], dtype='<U18'), array([['S7', 'Directions 1.58860488', 'frame_1361.jpg']], dtype='<U21'), array([['S1', 'Walking 1.58860488', 'frame_1081.jpg']], dtype='<U18'), array([['S11', 'Sitting 1.54138969', 'frame_721.jpg']], dtype='<U18'), array([['S5', 'Discussion 2.58860488', 'frame_4641.jpg']], dtype='<U21'), array([['S7', 'Greeting 1.55011271', 'frame_861.jpg']], dtype='<U19'), array([['S1', 'Sitting 1.58860488', 'frame_1101.jpg']], dtype='<U18'), array([['S7', 'Walking 2.58860488', 'frame_2841.jpg']], dtype='<U18'), array([['S1', 'Greeting.58860488', 'frame_521.jpg']], dtype='<U17'), array([['S7', 'SittingDown 1.58860488', 'frame_5381.jpg']], dtype='<U22'), array([['S1', 'Waiting.58860488', 'frame_1321.jpg']], dtype='<U16'), array([['S7', 'Walking 2.54138969', 'frame_1541.jpg']], dtype='<U18'), array([['S5', 'Smoking.58860488', 'frame_2721.jpg']], dtype='<U16'), array([['S9', 'Eating 1.55011271', 'frame_1381.jpg']], dtype='<U17'), array([['S5', 'Eating 1.60457274', 'frame_2101.jpg']], dtype='<U17'), array([['S9', 'Phoning.60457274', 'frame_821.jpg']], dtype='<U16'), array([['S7', 'Sitting 1.58860488', 'frame_1721.jpg']], dtype='<U18'), array([['S9', 'Posing.58860488', 'frame_1481.jpg']], dtype='<U15'), array([['S1', 'Waiting 1.54138969', 'frame_241.jpg']], dtype='<U18'), array([['S7', 'SittingDown 1.58860488', 'frame_5361.jpg']], dtype='<U22'), array([['S7', 'SittingDown 1.60457274', 'frame_1061.jpg']], dtype='<U22'), array([['S9', 'Sitting 1.58860488', 'frame_201.jpg']], dtype='<U18'), array([['S1', 'Phoning 1.60457274', 'frame_2361.jpg']], dtype='<U18'), array([['S7', 'Eating 1.60457274', 'frame_2601.jpg']], dtype='<U17'), array([['S9', 'Greeting 1.54138969', 'frame_681.jpg']], dtype='<U19'), array([['S9', 'Phoning 1.60457274', 'frame_1601.jpg']], dtype='<U18'), array([['S7', 'WalkDog 1.58860488', 'frame_2281.jpg']], dtype='<U18'), array([['S5', 'Posing.60457274', 'frame_1761.jpg']], dtype='<U15'), array([['S9', 'Phoning.54138969', 'frame_1181.jpg']], dtype='<U16'), array([['S7', 'Phoning.54138969', 'frame_2361.jpg']], dtype='<U16'), array([['S5', 'Sitting.54138969', 'frame_3701.jpg']], dtype='<U16'), array([['S9', 'Eating.60457274', 'frame_2141.jpg']], dtype='<U15'), array([['S9', 'Eating 1.58860488', 'frame_1021.jpg']], dtype='<U17'), array([['S5', 'Sitting.58860488', 'frame_1201.jpg']], dtype='<U16'), array([['S1', 'WalkTogether.58860488', 'frame_621.jpg']], dtype='<U21'), array([['S7', 'Waiting 2.58860488', 'frame_821.jpg']], dtype='<U18'), array([['S7', 'Greeting 1.54138969', 'frame_521.jpg']], dtype='<U19'), array([['S5', 'Photo.60457274', 'frame_3221.jpg']], dtype='<U14'), array([['S7', 'WalkDog.55011271', 'frame_381.jpg']], dtype='<U16'), array([['S5', 'Posing.58860488', 'frame_1081.jpg']], dtype='<U15'), array([['S9', 'WalkDog 1.58860488', 'frame_261.jpg']], dtype='<U18'), array([['S1', 'Discussion.60457274', 'frame_1081.jpg']], dtype='<U19'), array([['S11', 'Sitting.54138969', 'frame_841.jpg']], dtype='<U16'), array([['S7', 'Eating.55011271', 'frame_2241.jpg']], dtype='<U15'), array([['S9', 'Sitting 1.60457274', 'frame_561.jpg']], dtype='<U18'), array([['S1', 'Sitting 1.54138969', 'frame_3241.jpg']], dtype='<U18'), array([['S5', 'Photo 2.60457274', 'frame_1921.jpg']], dtype='<U16'), array([['S1', 'Directions 1.55011271', 'frame_1021.jpg']], dtype='<U21'), array([['S5', 'Waiting 2.54138969', 'frame_1381.jpg']], dtype='<U18'), array([['S7', 'Sitting 1.54138969', 'frame_381.jpg']], dtype='<U18'), array([['S7', 'SittingDown 1.60457274', 'frame_3221.jpg']], dtype='<U22'), array([['S9', 'Posing 1.60457274', 'frame_1881.jpg']], dtype='<U17'), array([['S7', 'Discussion.55011271', 'frame_2441.jpg']], dtype='<U19'), array([['S7', 'WalkDog 1.58860488', 'frame_2121.jpg']], dtype='<U18'), array([['S7', 'SittingDown 1.55011271', 'frame_281.jpg']], dtype='<U22'), array([['S11', 'Sitting.54138969', 'frame_1781.jpg']], dtype='<U16'), array([['S11', 'SittingDown.58860488', 'frame_1401.jpg']], dtype='<U20'), array([['S11', 'WalkTogether 1.60457274', 'frame_961.jpg']], dtype='<U23'), array([['S9', 'Discussion 2.60457274', 'frame_161.jpg']], dtype='<U21'), array([['S7', 'Directions 1.58860488', 'frame_2041.jpg']], dtype='<U21'), array([['S7', 'Purchases.60457274', 'frame_81.jpg']], dtype='<U18'), array([['S7', 'Greeting 1.54138969', 'frame_901.jpg']], dtype='<U19'), array([['S7', 'Waiting 2.60457274', 'frame_141.jpg']], dtype='<U18'), array([['S1', 'WalkingDog.55011271', 'frame_1681.jpg']], dtype='<U19'), array([['S7', 'WalkDog 1.60457274', 'frame_1461.jpg']], dtype='<U18'), array([['S5', 'Discussion 3.60457274', 'frame_4001.jpg']], dtype='<U21'), array([['S5', 'Phoning 1.55011271', 'frame_2341.jpg']], dtype='<U18'), array([['S11', 'Purchases 1.58860488', 'frame_861.jpg']], dtype='<U20'), array([['S11', 'Discussion 1.58860488', 'frame_221.jpg']], dtype='<U21'), array([['S1', 'Purchases 1.55011271', 'frame_141.jpg']], dtype='<U20'), array([['S9', 'Directions.55011271', 'frame_1121.jpg']], dtype='<U19'), array([['S9', 'Walking 1.60457274', 'frame_1221.jpg']], dtype='<U18'), array([['S1', 'Walking.55011271', 'frame_1941.jpg']], dtype='<U16'), array([['S5', 'Walking 1.60457274', 'frame_2221.jpg']], dtype='<U18'), array([['S7', 'Phoning.60457274', 'frame_3481.jpg']], dtype='<U16'), array([['S7', 'Posing.55011271', 'frame_2801.jpg']], dtype='<U15'), array([['S9', 'Walking 1.54138969', 'frame_161.jpg']], dtype='<U18'), array([['S11', 'Eating 1.54138969', 'frame_401.jpg']], dtype='<U17'), array([['S11', 'Walking 1.54138969', 'frame_1141.jpg']], dtype='<U18'), array([['S5', 'SittingDown.54138969', 'frame_1721.jpg']], dtype='<U20'), array([['S1', 'SittingDown.54138969', 'frame_2141.jpg']], dtype='<U20'), array([['S5', 'Photo 2.55011271', 'frame_2601.jpg']], dtype='<U16'), array([['S7', 'Phoning.54138969', 'frame_61.jpg']], dtype='<U16'), array([['S5', 'Posing 1.54138969', 'frame_2021.jpg']], dtype='<U17'), array([['S5', 'Photo.58860488', 'frame_1881.jpg']], dtype='<U14'), array([['S5', 'SittingDown.60457274', 'frame_2421.jpg']], dtype='<U20'), array([['S1', 'Phoning 1.55011271', 'frame_2521.jpg']], dtype='<U18'), array([['S7', 'Smoking.55011271', 'frame_601.jpg']], dtype='<U16'), array([['S5', 'Sitting.60457274', 'frame_2421.jpg']], dtype='<U16'), array([['S1', 'Phoning 1.54138969', 'frame_2221.jpg']], dtype='<U18'), array([['S7', 'Walking 1.55011271', 'frame_3381.jpg']], dtype='<U18'), array([['S9', 'Phoning 1.60457274', 'frame_121.jpg']], dtype='<U18'), array([['S9', 'Discussion 2.60457274', 'frame_21.jpg']], dtype='<U21'), array([['S1', 'Phoning 1.60457274', 'frame_541.jpg']], dtype='<U18'), array([['S7', 'Waiting 1.58860488', 'frame_2881.jpg']], dtype='<U18'), array([['S1', 'Phoning 1.58860488', 'frame_1781.jpg']], dtype='<U18'), array([['S1', 'SittingDown.54138969', 'frame_241.jpg']], dtype='<U20'), array([['S5', 'Greeting 2.58860488', 'frame_1641.jpg']], dtype='<U19'), array([['S5', 'Discussion 3.58860488', 'frame_781.jpg']], dtype='<U21'), array([['S5', 'Photo.60457274', 'frame_1281.jpg']], dtype='<U14'), array([['S5', 'Waiting 1.55011271', 'frame_2301.jpg']], dtype='<U18'), array([['S5', 'Discussion 3.60457274', 'frame_1321.jpg']], dtype='<U21'), array([['S9', 'SittingDown 1.60457274', 'frame_1081.jpg']], dtype='<U22'), array([['S7', 'Purchases.58860488', 'frame_281.jpg']], dtype='<U18'), array([['S9', 'Photo 1.54138969', 'frame_361.jpg']], dtype='<U16'), array([['S11', 'SittingDown 1.60457274', 'frame_1541.jpg']], dtype='<U22'), array([['S7', 'Photo.58860488', 'frame_2021.jpg']], dtype='<U14'), array([['S9', 'Phoning 1.60457274', 'frame_281.jpg']], dtype='<U18'), array([['S11', 'Posing 1.58860488', 'frame_241.jpg']], dtype='<U17'), array([['S11', 'WalkTogether.54138969', 'frame_221.jpg']], dtype='<U21'), array([['S7', 'WalkTogether.60457274', 'frame_121.jpg']], dtype='<U21'), array([['S7', 'Directions 1.60457274', 'frame_41.jpg']], dtype='<U21'), array([['S5', 'Phoning 1.55011271', 'frame_341.jpg']], dtype='<U18'), array([['S11', 'Greeting 2.54138969', 'frame_261.jpg']], dtype='<U19'), array([['S7', 'Walking 1.58860488', 'frame_1141.jpg']], dtype='<U18'), array([['S7', 'Sitting 1.55011271', 'frame_4461.jpg']], dtype='<U18'), array([['S5', 'Discussion 3.58860488', 'frame_4041.jpg']], dtype='<U21'), array([['S9', 'WalkDog 1.55011271', 'frame_121.jpg']], dtype='<U18'), array([['S9', 'Eating 1.55011271', 'frame_601.jpg']], dtype='<U17'), array([['S9', 'Smoking.60457274', 'frame_1821.jpg']], dtype='<U16'), array([['S1', 'Phoning.60457274', 'frame_1121.jpg']], dtype='<U16'), array([['S5', 'Eating 1.55011271', 'frame_701.jpg']], dtype='<U17'), array([['S5', 'Discussion 3.58860488', 'frame_4501.jpg']], dtype='<U21'), array([['S1', 'Purchases.54138969', 'frame_201.jpg']], dtype='<U18'), array([['S5', 'Sitting.54138969', 'frame_2441.jpg']], dtype='<U16'), array([['S5', 'Sitting.60457274', 'frame_3401.jpg']], dtype='<U16'), array([['S7', 'SittingDown 1.58860488', 'frame_3021.jpg']], dtype='<U22'), array([['S7', 'Eating 1.60457274', 'frame_3501.jpg']], dtype='<U17'), array([['S9', 'Sitting.54138969', 'frame_2101.jpg']], dtype='<U16'), array([['S5', 'Eating.55011271', 'frame_61.jpg']], dtype='<U15'), array([['S5', 'Walking.54138969', 'frame_921.jpg']], dtype='<U16'), array([['S7', 'Discussion 1.54138969', 'frame_1301.jpg']], dtype='<U21'), array([['S7', 'SittingDown 1.55011271', 'frame_1121.jpg']], dtype='<U22'), array([['S11', 'SittingDown.54138969', 'frame_481.jpg']], dtype='<U20'), array([['S7', 'Posing 1.60457274', 'frame_21.jpg']], dtype='<U17'), array([['S11', 'Discussion 1.54138969', 'frame_1921.jpg']], dtype='<U21'), array([['S9', 'SittingDown.60457274', 'frame_1001.jpg']], dtype='<U20'), array([['S1', 'Discussion 1.58860488', 'frame_1121.jpg']], dtype='<U21'), array([['S5', 'Posing 1.54138969', 'frame_461.jpg']], dtype='<U17'), array([['S5', 'Sitting.55011271', 'frame_2661.jpg']], dtype='<U16'), array([['S5', 'Sitting 1.58860488', 'frame_2721.jpg']], dtype='<U18'), array([['S7', 'Walking 1.55011271', 'frame_2901.jpg']], dtype='<U18'), array([['S11', 'Waiting.58860488', 'frame_1081.jpg']], dtype='<U16'), array([['S7', 'SittingDown 1.54138969', 'frame_641.jpg']], dtype='<U22'), array([['S1', 'Eating 2.58860488', 'frame_1541.jpg']], dtype='<U17'), array([['S5', 'Smoking 1.58860488', 'frame_721.jpg']], dtype='<U18'), array([['S9', 'Posing 1.60457274', 'frame_1841.jpg']], dtype='<U17'), array([['S7', 'Photo.55011271', 'frame_1981.jpg']], dtype='<U14'), array([['S11', 'Sitting 1.55011271', 'frame_1361.jpg']], dtype='<U18'), array([['S5', 'Walking.60457274', 'frame_2481.jpg']], dtype='<U16'), array([['S7', 'Discussion 1.60457274', 'frame_5101.jpg']], dtype='<U21'), array([['S5', 'Directions 1.60457274', 'frame_2421.jpg']], dtype='<U21'), array([['S1', 'Purchases 1.54138969', 'frame_1021.jpg']], dtype='<U20'), array([['S7', 'Sitting 1.60457274', 'frame_1801.jpg']], dtype='<U18'), array([['S9', 'Walking 1.60457274', 'frame_2181.jpg']], dtype='<U18'), array([['S5', 'Phoning.58860488', 'frame_181.jpg']], dtype='<U16'), array([['S5', 'Greeting 2.60457274', 'frame_341.jpg']], dtype='<U19'), array([['S7', 'Purchases.54138969', 'frame_401.jpg']], dtype='<U18'), array([['S5', 'Smoking 1.55011271', 'frame_141.jpg']], dtype='<U18'), array([['S7', 'Phoning 2.55011271', 'frame_521.jpg']], dtype='<U18'), array([['S11', 'Waiting.54138969', 'frame_1521.jpg']], dtype='<U16'), array([['S7', 'Phoning 2.60457274', 'frame_1421.jpg']], dtype='<U18'), array([['S11', 'Photo.60457274', 'frame_1041.jpg']], dtype='<U14'), array([['S5', 'Sitting.60457274', 'frame_941.jpg']], dtype='<U16'), array([['S1', 'Waiting.58860488', 'frame_581.jpg']], dtype='<U16'), array([['S7', 'Purchases.54138969', 'frame_1101.jpg']], dtype='<U18'), array([['S9', 'Smoking 1.54138969', 'frame_921.jpg']], dtype='<U18'), array([['S7', 'Photo 1.58860488', 'frame_1181.jpg']], dtype='<U16'), array([['S1', 'Smoking 1.58860488', 'frame_981.jpg']], dtype='<U18'), array([['S1', 'Eating 2.60457274', 'frame_1741.jpg']], dtype='<U17'), array([['S5', 'Directions 1.60457274', 'frame_2541.jpg']], dtype='<U21'), array([['S9', 'Directions 1.54138969', 'frame_2101.jpg']], dtype='<U21'), array([['S7', 'Directions.58860488', 'frame_1121.jpg']], dtype='<U19'), array([['S5', 'Waiting 1.60457274', 'frame_61.jpg']], dtype='<U18'), array([['S9', 'Phoning.55011271', 'frame_2181.jpg']], dtype='<U16'), array([['S5', 'Posing.55011271', 'frame_1701.jpg']], dtype='<U15'), array([['S7', 'Walking 1.55011271', 'frame_561.jpg']], dtype='<U18'), array([['S9', 'Posing.58860488', 'frame_321.jpg']], dtype='<U15'), array([['S7', 'Walking 1.55011271', 'frame_621.jpg']], dtype='<U18'), array([['S11', 'Eating 1.58860488', 'frame_2001.jpg']], dtype='<U17'), array([['S11', 'Photo.55011271', 'frame_781.jpg']], dtype='<U14'), array([['S11', 'WalkDog 1.58860488', 'frame_561.jpg']], dtype='<U18'), array([['S5', 'Discussion 3.60457274', 'frame_1841.jpg']], dtype='<U21'), array([['S1', 'Greeting 1.54138969', 'frame_1.jpg']], dtype='<U19'), array([['S7', 'Eating.58860488', 'frame_1721.jpg']], dtype='<U15'), array([['S1', 'Discussion.58860488', 'frame_3441.jpg']], dtype='<U19'), array([['S11', 'Phoning 2.60457274', 'frame_2121.jpg']], dtype='<U18'), array([['S11', 'Phoning 2.55011271', 'frame_1061.jpg']], dtype='<U18'), array([['S5', 'Walking 1.55011271', 'frame_81.jpg']], dtype='<U18'), array([['S7', 'SittingDown 1.58860488', 'frame_41.jpg']], dtype='<U22'), array([['S5', 'Sitting.54138969', 'frame_1941.jpg']], dtype='<U16'), array([['S9', 'Eating.60457274', 'frame_1261.jpg']], dtype='<U15'), array([['S7', 'Walking 2.58860488', 'frame_2561.jpg']], dtype='<U18'), array([['S7', 'Discussion.60457274', 'frame_261.jpg']], dtype='<U19'), array([['S1', 'Discussion 1.55011271', 'frame_2381.jpg']], dtype='<U21'), array([['S11', 'Photo 1.60457274', 'frame_481.jpg']], dtype='<U16'), array([['S5', 'Directions 1.60457274', 'frame_1701.jpg']], dtype='<U21'), array([['S7', 'Waiting 2.55011271', 'frame_4001.jpg']], dtype='<U18'), array([['S7', 'WalkDog 1.58860488', 'frame_61.jpg']], dtype='<U18'), array([['S5', 'Sitting.60457274', 'frame_321.jpg']], dtype='<U16'), array([['S7', 'Eating 1.54138969', 'frame_2521.jpg']], dtype='<U17'), array([['S5', 'Phoning 1.60457274', 'frame_301.jpg']], dtype='<U18'), array([['S5', 'Walking 1.58860488', 'frame_581.jpg']], dtype='<U18'), array([['S5', 'Eating 1.54138969', 'frame_2341.jpg']], dtype='<U17'), array([['S5', 'WalkDog 1.55011271', 'frame_1081.jpg']], dtype='<U18'), array([['S5', 'Purchases 1.58860488', 'frame_2321.jpg']], dtype='<U20'), array([['S5', 'Walking.60457274', 'frame_901.jpg']], dtype='<U16'), array([['S1', 'Purchases.54138969', 'frame_121.jpg']], dtype='<U18'), array([['S11', 'Greeting.60457274', 'frame_1601.jpg']], dtype='<U17'), array([['S7', 'SittingDown.60457274', 'frame_3781.jpg']], dtype='<U20'), array([['S1', 'WalkTogether.54138969', 'frame_861.jpg']], dtype='<U21'), array([['S1', 'Eating 2.60457274', 'frame_2021.jpg']], dtype='<U17'), array([['S7', 'SittingDown 1.58860488', 'frame_3101.jpg']], dtype='<U22'), array([['S5', 'SittingDown.58860488', 'frame_941.jpg']], dtype='<U20'), array([['S5', 'Sitting.55011271', 'frame_3461.jpg']], dtype='<U16'), array([['S5', 'SittingDown 1.60457274', 'frame_1021.jpg']], dtype='<U22'), array([['S5', 'Walking.54138969', 'frame_1441.jpg']], dtype='<U16'), array([['S5', 'Photo 2.60457274', 'frame_2461.jpg']], dtype='<U16'), array([['S11', 'Greeting.60457274', 'frame_1721.jpg']], dtype='<U17'), array([['S11', 'Eating 1.58860488', 'frame_661.jpg']], dtype='<U17'), array([['S7', 'SittingDown 1.58860488', 'frame_181.jpg']], dtype='<U22'), array([['S7', 'Walking 1.54138969', 'frame_821.jpg']], dtype='<U18'), array([['S5', 'SittingDown 1.55011271', 'frame_221.jpg']], dtype='<U22'), array([['S9', 'Eating.58860488', 'frame_1001.jpg']], dtype='<U15'), array([['S1', 'Sitting 2.55011271', 'frame_1761.jpg']], dtype='<U18'), array([['S1', 'Phoning 1.55011271', 'frame_2601.jpg']], dtype='<U18'), array([['S9', 'SittingDown.60457274', 'frame_501.jpg']], dtype='<U20'), array([['S9', 'Waiting 1.60457274', 'frame_541.jpg']], dtype='<U18'), array([['S5', 'Waiting 1.54138969', 'frame_4141.jpg']], dtype='<U18'), array([['S11', 'Sitting.60457274', 'frame_2141.jpg']], dtype='<U16'), array([['S7', 'Discussion 1.58860488', 'frame_5341.jpg']], dtype='<U21'), array([['S7', 'Phoning 2.54138969', 'frame_3961.jpg']], dtype='<U18'), array([['S7', 'Directions.55011271', 'frame_2161.jpg']], dtype='<U19'), array([['S7', 'WalkTogether 1.58860488', 'frame_2281.jpg']], dtype='<U23'), array([['S7', 'Phoning 2.60457274', 'frame_2161.jpg']], dtype='<U18'), array([['S5', 'Photo.55011271', 'frame_1181.jpg']], dtype='<U14'), array([['S5', 'WalkTogether.58860488', 'frame_381.jpg']], dtype='<U21'), array([['S11', 'Phoning 3.55011271', 'frame_1881.jpg']], dtype='<U18'), array([['S5', 'WalkDog 1.54138969', 'frame_521.jpg']], dtype='<U18'), array([['S5', 'Discussion 2.55011271', 'frame_1821.jpg']], dtype='<U21'), array([['S7', 'SittingDown.55011271', 'frame_2521.jpg']], dtype='<U20'), array([['S9', 'Smoking.54138969', 'frame_321.jpg']], dtype='<U16'), array([['S7', 'Greeting 1.60457274', 'frame_261.jpg']], dtype='<U19'), array([['S5', 'Walking 1.55011271', 'frame_1741.jpg']], dtype='<U18'), array([['S11', 'Sitting 1.60457274', 'frame_541.jpg']], dtype='<U18'), array([['S5', 'Phoning 1.54138969', 'frame_1041.jpg']], dtype='<U18'), array([['S11', 'Greeting.55011271', 'frame_1541.jpg']], dtype='<U17'), array([['S7', 'Posing 1.54138969', 'frame_101.jpg']], dtype='<U17'), array([['S5', 'Walking 1.54138969', 'frame_2141.jpg']], dtype='<U18'), array([['S1', 'Directions 1.58860488', 'frame_1041.jpg']], dtype='<U21'), array([['S5', 'Discussion 3.54138969', 'frame_3841.jpg']], dtype='<U21'), array([['S1', 'Greeting.55011271', 'frame_741.jpg']], dtype='<U17'), array([['S1', 'Walking 1.54138969', 'frame_2221.jpg']], dtype='<U18'), array([['S9', 'WalkTogether 1.55011271', 'frame_821.jpg']], dtype='<U23'), array([['S5', 'Discussion 2.58860488', 'frame_4881.jpg']], dtype='<U21'), array([['S9', 'Discussion 2.58860488', 'frame_1741.jpg']], dtype='<U21'), array([['S7', 'Purchases 1.60457274', 'frame_181.jpg']], dtype='<U20'), array([['S5', 'WalkTogether 1.60457274', 'frame_321.jpg']], dtype='<U23'), array([['S5', 'Purchases.60457274', 'frame_2821.jpg']], dtype='<U18'), array([['S7', 'Discussion 1.55011271', 'frame_3501.jpg']], dtype='<U21'), array([['S9', 'Greeting.60457274', 'frame_1101.jpg']], dtype='<U17'), array([['S1', 'Directions.60457274', 'frame_861.jpg']], dtype='<U19'), array([['S5', 'Sitting.55011271', 'frame_3161.jpg']], dtype='<U16'), array([['S9', 'WalkTogether.60457274', 'frame_121.jpg']], dtype='<U21'), array([['S9', 'Phoning.60457274', 'frame_1321.jpg']], dtype='<U16'), array([['S9', 'Purchases.58860488', 'frame_1241.jpg']], dtype='<U18'), array([['S7', 'Smoking.55011271', 'frame_3241.jpg']], dtype='<U16'), array([['S11', 'Sitting 1.60457274', 'frame_1541.jpg']], dtype='<U18'), array([['S9', 'Smoking 1.58860488', 'frame_2041.jpg']], dtype='<U18'), array([['S7', 'Sitting.54138969', 'frame_1221.jpg']], dtype='<U16'), array([['S7', 'WalkTogether.60457274', 'frame_21.jpg']], dtype='<U21'), array([['S11', 'Smoking 2.55011271', 'frame_21.jpg']], dtype='<U18'), array([['S9', 'WalkDog.54138969', 'frame_1901.jpg']], dtype='<U16'), array([['S7', 'Discussion.54138969', 'frame_741.jpg']], dtype='<U19'), array([['S5', 'Photo 2.58860488', 'frame_1141.jpg']], dtype='<U16'), array([['S7', 'Sitting.55011271', 'frame_1161.jpg']], dtype='<U16'), array([['S11', 'WalkTogether 1.54138969', 'frame_761.jpg']], dtype='<U23'), array([['S1', 'SittingDown.54138969', 'frame_1241.jpg']], dtype='<U20'), array([['S11', 'Discussion 2.54138969', 'frame_1901.jpg']], dtype='<U21'), array([['S11', 'Sitting.58860488', 'frame_1661.jpg']], dtype='<U16'), array([['S11', 'Sitting.58860488', 'frame_1561.jpg']], dtype='<U16'), array([['S7', 'SittingDown 1.55011271', 'frame_5841.jpg']], dtype='<U22'), array([['S5', 'Sitting 1.58860488', 'frame_261.jpg']], dtype='<U18'), array([['S7', 'Greeting 1.54138969', 'frame_1761.jpg']], dtype='<U19'), array([['S5', 'Discussion 2.54138969', 'frame_101.jpg']], dtype='<U21'), array([['S9', 'WalkTogether.54138969', 'frame_241.jpg']], dtype='<U21'), array([['S1', 'Discussion 1.55011271', 'frame_3181.jpg']], dtype='<U21'), array([['S7', 'Waiting 1.60457274', 'frame_1321.jpg']], dtype='<U18'), array([['S7', 'Posing.55011271', 'frame_2721.jpg']], dtype='<U15'), array([['S1', 'Phoning 1.60457274', 'frame_781.jpg']], dtype='<U18'), array([['S7', 'Purchases 1.58860488', 'frame_301.jpg']], dtype='<U20'), array([['S1', 'Posing 1.60457274', 'frame_981.jpg']], dtype='<U17'), array([['S5', 'Discussion 2.58860488', 'frame_3061.jpg']], dtype='<U21'), array([['S7', 'Waiting 2.58860488', 'frame_3501.jpg']], dtype='<U18'), array([['S5', 'Phoning.58860488', 'frame_21.jpg']], dtype='<U16'), array([['S1', 'Waiting.58860488', 'frame_441.jpg']], dtype='<U16'), array([['S7', 'Directions.54138969', 'frame_2721.jpg']], dtype='<U19'), array([['S7', 'Eating 1.58860488', 'frame_2761.jpg']], dtype='<U17'), array([['S7', 'Waiting 1.60457274', 'frame_641.jpg']], dtype='<U18'), array([['S9', 'Sitting.58860488', 'frame_1201.jpg']], dtype='<U16'), array([['S5', 'Walking 1.55011271', 'frame_1561.jpg']], dtype='<U18'), array([['S11', 'Posing.60457274', 'frame_181.jpg']], dtype='<U15'), array([['S1', 'Eating 2.54138969', 'frame_1721.jpg']], dtype='<U17'), array([['S5', 'Waiting 1.54138969', 'frame_3121.jpg']], dtype='<U18'), array([['S7', 'Discussion 1.54138969', 'frame_4301.jpg']], dtype='<U21'), array([['S11', 'Purchases 1.60457274', 'frame_781.jpg']], dtype='<U20'), array([['S11', 'Discussion 2.55011271', 'frame_921.jpg']], dtype='<U21'), array([['S9', 'Greeting.60457274', 'frame_901.jpg']], dtype='<U17'), array([['S5', 'WalkDog.60457274', 'frame_1081.jpg']], dtype='<U16'), array([['S1', 'Greeting.60457274', 'frame_981.jpg']], dtype='<U17'), array([['S7', 'Eating 1.55011271', 'frame_2661.jpg']], dtype='<U17'), array([['S7', 'Eating.60457274', 'frame_921.jpg']], dtype='<U15'), array([['S5', 'WalkDog 1.54138969', 'frame_281.jpg']], dtype='<U18'), array([['S5', 'Directions 1.60457274', 'frame_1281.jpg']], dtype='<U21'), array([['S7', 'SittingDown 1.54138969', 'frame_1941.jpg']], dtype='<U22'), array([['S1', 'WalkingDog.55011271', 'frame_1421.jpg']], dtype='<U19'), array([['S1', 'Walking 1.55011271', 'frame_1621.jpg']], dtype='<U18'), array([['S5', 'Eating.60457274', 'frame_121.jpg']], dtype='<U15'), array([['S11', 'Waiting.55011271', 'frame_661.jpg']], dtype='<U16'), array([['S7', 'Phoning.54138969', 'frame_1661.jpg']], dtype='<U16'), array([['S5', 'Directions 2.58860488', 'frame_701.jpg']], dtype='<U21'), array([['S7', 'SittingDown.55011271', 'frame_681.jpg']], dtype='<U20'), array([['S5', 'Sitting 1.60457274', 'frame_1361.jpg']], dtype='<U18'), array([['S5', 'Sitting.58860488', 'frame_1661.jpg']], dtype='<U16'), array([['S9', 'Sitting 1.58860488', 'frame_1181.jpg']], dtype='<U18'), array([['S9', 'Waiting 1.55011271', 'frame_301.jpg']], dtype='<U18'), array([['S9', 'Photo 1.58860488', 'frame_1081.jpg']], dtype='<U16'), array([['S11', 'Phoning 3.55011271', 'frame_1361.jpg']], dtype='<U18'), array([['S1', 'Eating.58860488', 'frame_2221.jpg']], dtype='<U15'), array([['S5', 'Walking.54138969', 'frame_2501.jpg']], dtype='<U16'), array([['S5', 'Sitting.58860488', 'frame_181.jpg']], dtype='<U16'), array([['S1', 'Sitting 2.55011271', 'frame_1941.jpg']], dtype='<U18'), array([['S5', 'Discussion 3.58860488', 'frame_4941.jpg']], dtype='<U21'), array([['S7', 'WalkTogether.60457274', 'frame_2181.jpg']], dtype='<U21'), array([['S1', 'Smoking.58860488', 'frame_2341.jpg']], dtype='<U16'), array([['S11', 'Discussion 2.55011271', 'frame_801.jpg']], dtype='<U21'), array([['S7', 'Smoking 1.55011271', 'frame_1981.jpg']], dtype='<U18'), array([['S9', 'WalkTogether.60457274', 'frame_321.jpg']], dtype='<U21'), array([['S7', 'Directions.54138969', 'frame_2081.jpg']], dtype='<U19'), array([['S9', 'Posing.60457274', 'frame_501.jpg']], dtype='<U15'), array([['S1', 'Smoking.58860488', 'frame_2081.jpg']], dtype='<U16'), array([['S5', 'Purchases.55011271', 'frame_2801.jpg']], dtype='<U18'), array([['S9', 'Discussion 1.60457274', 'frame_1221.jpg']], dtype='<U21'), array([['S5', 'Greeting 2.60457274', 'frame_1.jpg']], dtype='<U19'), array([['S1', 'WalkingDog 1.55011271', 'frame_761.jpg']], dtype='<U21'), array([['S1', 'Waiting 1.55011271', 'frame_1341.jpg']], dtype='<U18'), array([['S5', 'Greeting 2.55011271', 'frame_3141.jpg']], dtype='<U19'), array([['S7', 'Directions.54138969', 'frame_1901.jpg']], dtype='<U19'), array([['S11', 'SittingDown 1.58860488', 'frame_1561.jpg']], dtype='<U22'), array([['S9', 'Eating 1.58860488', 'frame_2201.jpg']], dtype='<U17'), array([['S1', 'Posing.60457274', 'frame_621.jpg']], dtype='<U15'), array([['S7', 'WalkDog.58860488', 'frame_2321.jpg']], dtype='<U16'), array([['S5', 'Sitting 1.60457274', 'frame_641.jpg']], dtype='<U18'), array([['S9', 'Greeting 1.55011271', 'frame_1641.jpg']], dtype='<U19'), array([['S7', 'Purchases.60457274', 'frame_601.jpg']], dtype='<U18'), array([['S7', 'Photo 1.55011271', 'frame_401.jpg']], dtype='<U16'), array([['S9', 'Purchases 1.54138969', 'frame_521.jpg']], dtype='<U20'), array([['S5', 'Walking.55011271', 'frame_361.jpg']], dtype='<U16'), array([['S7', 'Sitting.55011271', 'frame_1761.jpg']], dtype='<U16'), array([['S7', 'Photo.55011271', 'frame_1721.jpg']], dtype='<U14'), array([['S9', 'SittingDown.54138969', 'frame_381.jpg']], dtype='<U20'), array([['S11', 'Posing 1.54138969', 'frame_21.jpg']], dtype='<U17'), array([['S7', 'Discussion 1.60457274', 'frame_3861.jpg']], dtype='<U21'), array([['S7', 'Smoking.58860488', 'frame_301.jpg']], dtype='<U16'), array([['S11', 'Eating.55011271', 'frame_1921.jpg']], dtype='<U15'), array([['S11', 'Smoking 2.55011271', 'frame_561.jpg']], dtype='<U18'), array([['S7', 'Posing.54138969', 'frame_2861.jpg']], dtype='<U15'), array([['S9', 'Smoking 1.60457274', 'frame_2041.jpg']], dtype='<U18'), array([['S9', 'Phoning 1.58860488', 'frame_1621.jpg']], dtype='<U18'), array([['S7', 'Photo.55011271', 'frame_861.jpg']], dtype='<U14'), array([['S1', 'Posing.58860488', 'frame_381.jpg']], dtype='<U15'), array([['S11', 'WalkDog.58860488', 'frame_21.jpg']], dtype='<U16'), array([['S11', 'Discussion 1.58860488', 'frame_2001.jpg']], dtype='<U21'), array([['S5', 'Discussion 2.58860488', 'frame_5261.jpg']], dtype='<U21'), array([['S7', 'Directions.60457274', 'frame_81.jpg']], dtype='<U19'), array([['S5', 'Smoking.58860488', 'frame_2261.jpg']], dtype='<U16'), array([['S7', 'Greeting.60457274', 'frame_1781.jpg']], dtype='<U17'), array([['S11', 'SittingDown.54138969', 'frame_421.jpg']], dtype='<U20'), array([['S9', 'Smoking.55011271', 'frame_1.jpg']], dtype='<U16'), array([['S1', 'Discussion 1.60457274', 'frame_941.jpg']], dtype='<U21'), array([['S7', 'Posing 1.58860488', 'frame_81.jpg']], dtype='<U17'), array([['S1', 'Sitting 2.55011271', 'frame_1801.jpg']], dtype='<U18'), array([['S11', 'WalkDog 1.58860488', 'frame_1101.jpg']], dtype='<U18'), array([['S1', 'Smoking 1.54138969', 'frame_81.jpg']], dtype='<U18'), array([['S5', 'Directions 1.60457274', 'frame_881.jpg']], dtype='<U21'), array([['S9', 'Discussion 2.55011271', 'frame_1241.jpg']], dtype='<U21'), array([['S1', 'Sitting 1.58860488', 'frame_521.jpg']], dtype='<U18'), array([['S9', 'Discussion 2.58860488', 'frame_1881.jpg']], dtype='<U21'), array([['S7', 'Sitting 1.55011271', 'frame_3741.jpg']], dtype='<U18'), array([['S1', 'Walking.60457274', 'frame_2801.jpg']], dtype='<U16'), array([['S9', 'Eating 1.54138969', 'frame_2101.jpg']], dtype='<U17'), array([['S7', 'Waiting 2.54138969', 'frame_4281.jpg']], dtype='<U18'), array([['S9', 'Posing.55011271', 'frame_1361.jpg']], dtype='<U15'), array([['S11', 'Sitting 1.58860488', 'frame_521.jpg']], dtype='<U18'), array([['S1', 'Directions 1.58860488', 'frame_641.jpg']], dtype='<U21'), array([['S5', 'Purchases.55011271', 'frame_1081.jpg']], dtype='<U18'), array([['S9', 'Posing.60457274', 'frame_341.jpg']], dtype='<U15'), array([['S7', 'WalkTogether 1.58860488', 'frame_201.jpg']], dtype='<U23'), array([['S7', 'Waiting 1.55011271', 'frame_3181.jpg']], dtype='<U18'), array([['S11', 'Greeting 2.55011271', 'frame_761.jpg']], dtype='<U19'), array([['S11', 'Photo.55011271', 'frame_1881.jpg']], dtype='<U14'), array([['S11', 'WalkDog.58860488', 'frame_281.jpg']], dtype='<U16'), array([['S5', 'WalkDog.58860488', 'frame_821.jpg']], dtype='<U16'), array([['S1', 'WalkingDog.54138969', 'frame_1341.jpg']], dtype='<U19'), array([['S1', 'Posing 1.54138969', 'frame_921.jpg']], dtype='<U17'), array([['S1', 'Waiting 1.55011271', 'frame_81.jpg']], dtype='<U18'), array([['S5', 'Smoking.55011271', 'frame_2161.jpg']], dtype='<U16'), array([['S9', 'Eating.60457274', 'frame_1381.jpg']], dtype='<U15'), array([['S5', 'WalkTogether 1.60457274', 'frame_2481.jpg']], dtype='<U23'), array([['S5', 'WalkTogether.54138969', 'frame_1101.jpg']], dtype='<U21'), array([['S9', 'Posing.55011271', 'frame_1761.jpg']], dtype='<U15'), array([['S1', 'Sitting 2.58860488', 'frame_2161.jpg']], dtype='<U18'), array([['S1', 'Smoking.58860488', 'frame_1361.jpg']], dtype='<U16'), array([['S11', 'Phoning 2.60457274', 'frame_741.jpg']], dtype='<U18'), array([['S5', 'SittingDown.58860488', 'frame_4401.jpg']], dtype='<U20'), array([['S7', 'WalkTogether.60457274', 'frame_2721.jpg']], dtype='<U21'), array([['S5', 'WalkTogether 1.58860488', 'frame_2581.jpg']], dtype='<U23'), array([['S5', 'Walking 1.54138969', 'frame_2801.jpg']], dtype='<U18'), array([['S5', 'Phoning 1.55011271', 'frame_921.jpg']], dtype='<U18'), array([['S7', 'Directions 1.58860488', 'frame_21.jpg']], dtype='<U21'), array([['S9', 'Waiting.60457274', 'frame_1601.jpg']], dtype='<U16'), array([['S7', 'Waiting 1.60457274', 'frame_2541.jpg']], dtype='<U18'), array([['S5', 'Smoking 1.54138969', 'frame_1941.jpg']], dtype='<U18'), array([['S7', 'Smoking 1.54138969', 'frame_1141.jpg']], dtype='<U18'), array([['S5', 'Waiting 2.54138969', 'frame_1621.jpg']], dtype='<U18'), array([['S5', 'WalkTogether.58860488', 'frame_2001.jpg']], dtype='<U21'), array([['S5', 'Waiting 1.55011271', 'frame_4281.jpg']], dtype='<U18'), array([['S11', 'Walking 1.58860488', 'frame_1461.jpg']], dtype='<U18'), array([['S7', 'SittingDown 1.55011271', 'frame_1501.jpg']], dtype='<U22'), array([['S5', 'Eating.60457274', 'frame_1481.jpg']], dtype='<U15'), array([['S9', 'Phoning 1.54138969', 'frame_2141.jpg']], dtype='<U18'), array([['S7', 'Greeting.54138969', 'frame_1301.jpg']], dtype='<U17'), array([['S7', 'SittingDown 1.55011271', 'frame_301.jpg']], dtype='<U22'), array([['S11', 'Purchases 1.55011271', 'frame_181.jpg']], dtype='<U20'), array([['S5', 'Walking 1.55011271', 'frame_2921.jpg']], dtype='<U18'), array([['S5', 'Smoking 1.58860488', 'frame_1841.jpg']], dtype='<U18'), array([['S1', 'Smoking.60457274', 'frame_1121.jpg']], dtype='<U16'), array([['S1', 'Phoning 1.55011271', 'frame_121.jpg']], dtype='<U18'), array([['S11', 'Waiting.55011271', 'frame_841.jpg']], dtype='<U16'), array([['S7', 'SittingDown.58860488', 'frame_2601.jpg']], dtype='<U20'), array([['S7', 'Waiting 1.60457274', 'frame_421.jpg']], dtype='<U18'), array([['S7', 'Smoking.54138969', 'frame_3701.jpg']], dtype='<U16'), array([['S1', 'Walking 1.60457274', 'frame_2641.jpg']], dtype='<U18'), array([['S7', 'Walking 1.60457274', 'frame_81.jpg']], dtype='<U18'), array([['S9', 'Phoning 1.60457274', 'frame_1421.jpg']], dtype='<U18'), array([['S1', 'Discussion.58860488', 'frame_2201.jpg']], dtype='<U19'), array([['S5', 'Eating 1.60457274', 'frame_961.jpg']], dtype='<U17'), array([['S11', 'WalkDog.55011271', 'frame_161.jpg']], dtype='<U16'), array([['S11', 'Waiting.54138969', 'frame_841.jpg']], dtype='<U16'), array([['S1', 'Eating 2.55011271', 'frame_861.jpg']], dtype='<U17'), array([['S5', 'Smoking 1.58860488', 'frame_61.jpg']], dtype='<U18'), array([['S7', 'Smoking.60457274', 'frame_3541.jpg']], dtype='<U16'), array([['S7', 'Posing 1.54138969', 'frame_1781.jpg']], dtype='<U17'), array([['S5', 'Walking 1.55011271', 'frame_121.jpg']], dtype='<U18'), array([['S7', 'Eating.58860488', 'frame_2841.jpg']], dtype='<U15'), array([['S5', 'Smoking 1.58860488', 'frame_3161.jpg']], dtype='<U18'), array([['S11', 'Greeting.55011271', 'frame_501.jpg']], dtype='<U17'), array([['S9', 'Waiting.58860488', 'frame_681.jpg']], dtype='<U16'), array([['S5', 'SittingDown 1.55011271', 'frame_1661.jpg']], dtype='<U22'), array([['S9', 'Directions.60457274', 'frame_21.jpg']], dtype='<U19'), array([['S7', 'Sitting.58860488', 'frame_1721.jpg']], dtype='<U16'), array([['S7', 'SittingDown 1.54138969', 'frame_4881.jpg']], dtype='<U22'), array([['S5', 'Sitting 1.54138969', 'frame_1681.jpg']], dtype='<U18'), array([['S9', 'Directions.60457274', 'frame_1401.jpg']], dtype='<U19'), array([['S5', 'Discussion 3.54138969', 'frame_4941.jpg']], dtype='<U21'), array([['S5', 'Sitting.54138969', 'frame_2401.jpg']], dtype='<U16'), array([['S11', 'Purchases 1.54138969', 'frame_261.jpg']], dtype='<U20')]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58tqC8Wn9XNh","executionInfo":{"status":"ok","timestamp":1638262814079,"user_tz":420,"elapsed":135,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"}},"outputId":"ad344bf8-ef18-46d3-f7f5-ef9f28b6af95"},"source":["# data = np.load('Posing_1.54138969_results.npy', allow_pickle=True)\n","# len(data)\n","# data[4][9]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0.07900667,  0.3255531 ,  0.7409295 ,  0.13318908,  0.37806144,\n","        0.01350871,  0.3620047 ,  0.21933106,  0.22547124, -0.04112568],\n","      dtype=float32)"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M_aGw1e72zQP","executionInfo":{"status":"ok","timestamp":1638259264048,"user_tz":420,"elapsed":135,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"}},"outputId":"d0a8230e-bec7-493b-825c-ffb4da53c2e8"},"source":["# ## experiment with yield\n","# def g(i):\n","#   for j in range(i):\n","#     yield j\n","\n","# for i in g(10):\n","#   print(i)\n","\n","# # it works"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8j_t5nhVWBeh","executionInfo":{"status":"ok","timestamp":1638235533254,"user_tz":420,"elapsed":425,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"}},"outputId":"a60c6e90-6b93-41a0-fc55-84c70698a719"},"source":["# # add a row in numpy array\n","# import numpy\n","# A = numpy.array([[0, 1, 2], [0, 2, 0]])\n","# A = numpy.expand_dims(A,axis=0)\n","# print(A.shape)\n","# newrow = numpy.array([[0,1,2], [0,1,2]])\n","# newrow = numpy.expand_dims(newrow, axis=0)\n","# A = numpy.vstack([A, newrow])\n","# print(A.shape)\n","# print(A)\n","\n","# l = [1,2,3]\n","# for i in l[1:]:\n","#   print(i)\n","\n","# import torch\n","# A = torch.from_numpy(A)\n","# print(A)\n","\n","\n","# B = numpy.array([0,1,2])\n","\n","# print(B.shape)\n","# C = numpy.array([1,2,3])\n","# B = numpy.vstack([B,C])\n","# print(B)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 2, 3)\n","(2, 2, 3)\n","[[[0 1 2]\n","  [0 2 0]]\n","\n"," [[0 1 2]\n","  [0 1 2]]]\n","2\n","3\n","tensor([[[0, 1, 2],\n","         [0, 2, 0]],\n","\n","        [[0, 1, 2],\n","         [0, 1, 2]]])\n","(3,)\n","[[0 1 2]\n"," [1 2 3]]\n"]}]},{"cell_type":"code","metadata":{"id":"GqYZBr18VDpq"},"source":["                ''' -1 for example '''\n","                # if dataset[central_idx - 1][0][0] == S:\n","                #     if dataset[central_idx - 1][0][1] == video:\n","\n","                #         # extract the frame number\n","                #         frame_name = dataset[central_idx - 1][0][2]\n","                #         frame_num = get_frame_num(fram_name)\n","                #         if frame_num == central_frame_num - 20:\n","                #             subject.append(dataset[central_idx - 1])\n","                #         else:\n","                #             subject.append(dataset[central_idx])\n","                #             print('the -1 of frame', central_frame_num, 'not found')\n","                    \n","                #     else:\n","                #         subject.append(dataset[central_idx])\n","                #         print('the -1 of frame', central_frame_num, 'not found'\n","                # else:\n","                #     subject.append(dataset[central_idx])\n","                #     print('the -1 of frame', central_frame_num, 'not found'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IOuK0Z1xs-nw"},"source":["# # reshape the training data\n","# import os\n","# import numpy as np\n","\n","\n","# i = 0\n","\n","# dir = '/content/drive/MyDrive/HME/H36M Data/Cropped Images/HMR Outputs/Structure 2_gt'\n","# foldernames_train = ['S1','S5','S7','S9','S11']\n","# for foldername in foldernames_train:\n","#     dir_path = dir + '/' + foldername\n","#     for filename in os.listdir(dir_path):\n","#         path = dir_path + '/' + filename\n","#         # print(path)\n","#         i += 1\n","#         dataset = np.load(path, allow_pickle=True)\n","#         dataset = np.transpose(dataset, (1,0))\n","#         if i == 1:  # the first one can't be stack\n","#             newdata = dataset\n","#         else:\n","#             newdata = np.vstack([newdata, dataset])\n","#         print(len(newdata))\n","#   print(filename, 'is the last file')\n","#   print(i)\n","\n","\n","    \n","# # print(len(dataset[:,4]))\n","# # np.concatenate((dataset[:,3], dataset[:,4]), axis = 1)\n","# # np.concatenate(dataset[0,3], dataset[0,4], axis = 0)\n","# # newdata = np.concatenate(dataset[:,3], dataset[:,4])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yk0ktqrutYLa"},"source":["# # check frame consistency\n","# # for i in range(len(newdata)):\n","# #     print(newdata[i][0])\n","\n","\n","# # save the data\n","# np.save('trainingdata',newdata)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QgkIM3jJ22Gn","executionInfo":{"status":"ok","timestamp":1638309534258,"user_tz":420,"elapsed":149,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"}},"outputId":"8e3fb717-1c6f-4e7f-8560-a07b66a91997"},"source":["# dataset = np.load('Directions 1.58860488_resultsgt.npy', allow_pickle=True)\n","# dataset = np.transpose(dataset, (1,0))\n","# dataset[0][0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['S1', 'Directions 1.58860488', 'frame_1.jpg']"]},"metadata":{},"execution_count":94}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"whqqCbMn2-un","executionInfo":{"status":"ok","timestamp":1638309600566,"user_tz":420,"elapsed":1749,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"}},"outputId":"9c9b0ff2-a7ad-4048-abe3-bc1ea95174ac"},"source":["# dataset = np.load('trainingdata.npy', allow_pickle=True)\n","# dataset[0][0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['S1', 'WalkingDog 1.54138969', 'frame_1.jpg']"]},"metadata":{},"execution_count":98}]}]}