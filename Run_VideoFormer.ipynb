{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25770,"status":"ok","timestamp":1639341569483,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"},"user_tz":420},"id":"BNE9zFLGjg8L","outputId":"fa5fb02b-55af-4d22-8761-dcbeaf415666"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive') "]},{"cell_type":"code","source":["# check GPU version\n","!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pOMTqC56Xsj5","executionInfo":{"status":"ok","timestamp":1639341573336,"user_tz":420,"elapsed":229,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"}},"outputId":"a4957f7b-2a13-4fe0-f293-4b55352a6702"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Dec 12 20:39:33 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   31C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1638873317863,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"},"user_tz":420},"id":"0pyOLHnqj8GG","outputId":"a96a9ba7-ac16-4bf7-ae73-e32e21a1fd8a"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/HME/Temporal-Transformer\n"]}],"source":["%cd /content/drive/MyDrive/HME/Temporal-Transformer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13810,"status":"ok","timestamp":1638873331671,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"},"user_tz":420},"id":"szBBLWdYmH2_","outputId":"1263b780-c437-4602-eb09-94941942bdc0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.3.2)\n","Requirement already satisfied: PyPI in /usr/local/lib/python3.7/dist-packages (2.1)\n","Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.4.12)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n","Requirement already satisfied: import-ipynb in /usr/local/lib/python3.7/dist-packages (0.1.3)\n"]}],"source":["# requirements installation\n","!pip install einops\n","!pip install PyPI\n","!pip install timm\n","!pip install import-ipynb\n","# !pip install ipynb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1182,"status":"ok","timestamp":1638873332851,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"},"user_tz":420},"id":"aoLWlar6FAcx","outputId":"83169c00-6504-4b02-d0be-ab8e12dbed7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["importing Jupyter notebook from /content/drive/MyDrive/HME/Temporal-Transformer/main/arguments.ipynb\n","importing Jupyter notebook from /content/drive/MyDrive/HME/Temporal-Transformer/main/plot_training_curve.ipynb\n","Namespace(batch_size=512, checkpoint='checkpoint', checkpoint_frequency=10, data_augmentation=True, dataset='h36m', dropout=0.0, epochs=200, evaluate='', export_training_curves=False, learning_rate=0.0001, lr_decay=0.99, number_of_frames='/root/.local/share/jupyter/runtime/kernel-635038bf-4216-49e9-8c04-1e780e4e658d.json', resume='', stride=1, subjects_test='S9,S11', subjects_train='S1,S5,S6,S7,S8')\n"]}],"source":["import import_ipynb\n","import torch.optim as optim\n","from main.arguments import parse_args\n","from main.plot_training_curve import train_plot, test_plot\n","import numpy as np\n","import os\n","\n","args = parse_args()\n","print(args)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3679,"status":"ok","timestamp":1638873336523,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"},"user_tz":420},"id":"j6v-cvqGchrm","outputId":"d1093349-3dc5-4782-ed79-80110c9ace92"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/HME/Temporal-Transformer\n","136\n","dividing data......\n","[array([['S6', 'Discussion 1.54138969', 'frame_1.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_21.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_41.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_61.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_81.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_101.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_121.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_141.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_161.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_181.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_201.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_221.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_241.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_261.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_281.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_301.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_321.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_341.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_361.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_381.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_401.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_421.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_441.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_461.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_481.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_501.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_521.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_541.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_561.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_581.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_601.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_621.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_641.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_661.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_681.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_701.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_721.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_741.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_761.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_781.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_801.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_821.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_841.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_861.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_881.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_901.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_921.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_941.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_961.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_981.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1001.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1021.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1041.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1061.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1081.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1101.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1121.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1141.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1161.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1181.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1201.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1221.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1241.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1261.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1281.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1301.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1321.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1341.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1361.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1381.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1401.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1421.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1441.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1461.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1481.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1501.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1521.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1541.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1561.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1581.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1601.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1621.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1641.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1661.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1681.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1701.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1721.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1741.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1761.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1781.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1801.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1821.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1841.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1861.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1881.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1901.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1921.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1941.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1961.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_1981.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2001.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2021.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2041.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2061.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2081.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2101.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2121.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2141.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2161.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2181.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2201.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2221.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2241.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2261.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2281.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2301.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2321.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2341.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2361.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2381.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2401.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2421.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2441.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2461.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2481.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2501.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2521.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2541.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2561.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2581.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2601.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2621.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2641.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2661.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2681.jpg']], dtype='<U21'), array([['S6', 'Discussion 1.54138969', 'frame_2701.jpg']], dtype='<U21')]\n","[3, 2, 8]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","dividing data......\n","torch.Size([512, 1, 3])\n","dividing data......\n","[array([['S7', 'Eating 1.60457274', 'frame_461.jpg']], dtype='<U17'), array([['S5', 'Photo 2.54138969', 'frame_761.jpg']], dtype='<U16'), array([['S7', 'Photo.54138969', 'frame_1701.jpg']], dtype='<U14'), array([['S7', 'Greeting.54138969', 'frame_961.jpg']], dtype='<U17'), array([['S11', 'Smoking.55011271', 'frame_1021.jpg']], dtype='<U16'), array([['S7', 'Directions.60457274', 'frame_1961.jpg']], dtype='<U19'), array([['S11', 'Discussion 1.55011271', 'frame_1881.jpg']], dtype='<U21'), array([['S11', 'SittingDown 1.60457274', 'frame_401.jpg']], dtype='<U22'), array([['S11', 'Smoking 2.60457274', 'frame_181.jpg']], dtype='<U18'), array([['S5', 'SittingDown.54138969', 'frame_981.jpg']], dtype='<U20'), array([['S7', 'Eating.60457274', 'frame_2221.jpg']], dtype='<U15'), array([['S1', 'Phoning 1.55011271', 'frame_1061.jpg']], dtype='<U18'), array([['S9', 'Waiting.60457274', 'frame_721.jpg']], dtype='<U16'), array([['S9', 'Posing 1.55011271', 'frame_801.jpg']], dtype='<U17'), array([['S1', 'WalkTogether.58860488', 'frame_881.jpg']], dtype='<U21'), array([['S1', 'Greeting.60457274', 'frame_261.jpg']], dtype='<U17'), array([['S9', 'Sitting 1.60457274', 'frame_161.jpg']], dtype='<U18'), array([['S9', 'Eating.55011271', 'frame_1341.jpg']], dtype='<U15'), array([['S5', 'Discussion 2.55011271', 'frame_3601.jpg']], dtype='<U21'), array([['S11', 'Discussion 1.54138969', 'frame_401.jpg']], dtype='<U21'), array([['S5', 'Photo.60457274', 'frame_1201.jpg']], dtype='<U14'), array([['S1', 'Phoning.54138969', 'frame_1421.jpg']], dtype='<U16'), array([['S1', 'Greeting.60457274', 'frame_821.jpg']], dtype='<U17'), array([['S11', 'Smoking.54138969', 'frame_2121.jpg']], dtype='<U16'), array([['S11', 'Eating 1.58860488', 'frame_1981.jpg']], dtype='<U17'), array([['S7', 'Posing 1.55011271', 'frame_1041.jpg']], dtype='<U17'), array([['S7', 'WalkTogether.54138969', 'frame_1481.jpg']], dtype='<U21'), array([['S7', 'Eating 1.60457274', 'frame_2181.jpg']], dtype='<U17'), array([['S7', 'Waiting 1.54138969', 'frame_841.jpg']], dtype='<U18'), array([['S9', 'Sitting 1.60457274', 'frame_1561.jpg']], dtype='<U18'), array([['S11', 'Purchases 1.54138969', 'frame_561.jpg']], dtype='<U20'), array([['S11', 'Photo 1.54138969', 'frame_961.jpg']], dtype='<U16'), array([['S7', 'Discussion 1.54138969', 'frame_3061.jpg']], dtype='<U21'), array([['S7', 'WalkTogether.54138969', 'frame_1981.jpg']], dtype='<U21'), array([['S5', 'Directions 1.60457274', 'frame_1041.jpg']], dtype='<U21'), array([['S1', 'Smoking.55011271', 'frame_241.jpg']], dtype='<U16'), array([['S9', 'Smoking 1.54138969', 'frame_1601.jpg']], dtype='<U18'), array([['S11', 'Smoking 2.55011271', 'frame_401.jpg']], dtype='<U18'), array([['S5', 'Walking 1.58860488', 'frame_281.jpg']], dtype='<U18'), array([['S11', 'Phoning 3.55011271', 'frame_621.jpg']], dtype='<U18'), array([['S7', 'Smoking 1.60457274', 'frame_2621.jpg']], dtype='<U18'), array([['S7', 'Discussion.60457274', 'frame_4941.jpg']], dtype='<U19'), array([['S11', 'Phoning 2.58860488', 'frame_2141.jpg']], dtype='<U18'), array([['S11', 'SittingDown.60457274', 'frame_501.jpg']], dtype='<U20'), array([['S1', 'Discussion.55011271', 'frame_3601.jpg']], dtype='<U19'), array([['S1', 'Eating.58860488', 'frame_1021.jpg']], dtype='<U15'), array([['S7', 'Greeting 1.60457274', 'frame_1421.jpg']], dtype='<U19'), array([['S11', 'Eating 1.58860488', 'frame_761.jpg']], dtype='<U17'), array([['S9', 'Walking 1.60457274', 'frame_1061.jpg']], dtype='<U18'), array([['S11', 'Discussion 2.60457274', 'frame_1021.jpg']], dtype='<U21'), array([['S7', 'WalkDog.60457274', 'frame_121.jpg']], dtype='<U16'), array([['S9', 'Smoking.58860488', 'frame_1021.jpg']], dtype='<U16'), array([['S11', 'Phoning 3.58860488', 'frame_1681.jpg']], dtype='<U18'), array([['S1', 'Sitting 1.58860488', 'frame_1941.jpg']], dtype='<U18'), array([['S5', 'Phoning 1.60457274', 'frame_761.jpg']], dtype='<U18'), array([['S5', 'Sitting.54138969', 'frame_2741.jpg']], dtype='<U16'), array([['S7', 'Walking 2.55011271', 'frame_3041.jpg']], dtype='<U18'), array([['S7', 'Discussion 1.54138969', 'frame_3901.jpg']], dtype='<U21'), array([['S7', 'SittingDown.55011271', 'frame_3941.jpg']], dtype='<U20'), array([['S5', 'Phoning 1.60457274', 'frame_1701.jpg']], dtype='<U18'), array([['S11', 'Discussion 2.58860488', 'frame_1861.jpg']], dtype='<U21'), array([['S9', 'Greeting 1.58860488', 'frame_1621.jpg']], dtype='<U19'), array([['S9', 'Greeting 1.58860488', 'frame_481.jpg']], dtype='<U19'), array([['S1', 'Waiting.58860488', 'frame_81.jpg']], dtype='<U16'), array([['S1', 'Posing 1.60457274', 'frame_501.jpg']], dtype='<U17'), array([['S7', 'Directions 1.60457274', 'frame_101.jpg']], dtype='<U21'), array([['S1', 'Sitting 1.54138969', 'frame_3001.jpg']], dtype='<U18'), array([['S7', 'SittingDown.54138969', 'frame_3881.jpg']], dtype='<U20'), array([['S9', 'SittingDown.58860488', 'frame_781.jpg']], dtype='<U20'), array([['S1', 'Waiting.60457274', 'frame_1461.jpg']], dtype='<U16'), array([['S7', 'Waiting 1.55011271', 'frame_4021.jpg']], dtype='<U18'), array([['S11', 'Greeting 2.55011271', 'frame_1141.jpg']], dtype='<U19'), array([['S11', 'Photo.55011271', 'frame_1041.jpg']], dtype='<U14'), array([['S9', 'WalkTogether.54138969', 'frame_381.jpg']], dtype='<U21'), array([['S9', 'Photo 1.60457274', 'frame_481.jpg']], dtype='<U16'), array([['S5', 'Smoking.60457274', 'frame_2881.jpg']], dtype='<U16'), array([['S1', 'Discussion.60457274', 'frame_1481.jpg']], dtype='<U19'), array([['S9', 'WalkTogether 1.60457274', 'frame_1361.jpg']], dtype='<U23'), array([['S11', 'WalkTogether.54138969', 'frame_1341.jpg']], dtype='<U21'), array([['S11', 'SittingDown 1.58860488', 'frame_1641.jpg']], dtype='<U22'), array([['S11', 'WalkTogether 1.55011271', 'frame_1721.jpg']], dtype='<U23'), array([['S5', 'Posing.60457274', 'frame_121.jpg']], dtype='<U15'), array([['S7', 'WalkDog 1.54138969', 'frame_1961.jpg']], dtype='<U18'), array([['S11', 'Waiting.54138969', 'frame_1121.jpg']], dtype='<U16'), array([['S5', 'Discussion 2.58860488', 'frame_1821.jpg']], dtype='<U21'), array([['S7', 'Discussion 1.55011271', 'frame_1101.jpg']], dtype='<U21'), array([['S9', 'Discussion 2.55011271', 'frame_121.jpg']], dtype='<U21'), array([['S11', 'Discussion 2.58860488', 'frame_1081.jpg']], dtype='<U21'), array([['S5', 'Phoning 1.60457274', 'frame_921.jpg']], dtype='<U18'), array([['S5', 'Posing.58860488', 'frame_841.jpg']], dtype='<U15'), array([['S9', 'Discussion 1.55011271', 'frame_441.jpg']], dtype='<U21'), array([['S9', 'Purchases 1.58860488', 'frame_701.jpg']], dtype='<U20'), array([['S7', 'WalkDog 1.55011271', 'frame_801.jpg']], dtype='<U18'), array([['S9', 'WalkDog.54138969', 'frame_1581.jpg']], dtype='<U16'), array([['S5', 'Photo.54138969', 'frame_361.jpg']], dtype='<U14'), array([['S11', 'SittingDown 1.60457274', 'frame_1721.jpg']], dtype='<U22'), array([['S7', 'Walking 1.54138969', 'frame_341.jpg']], dtype='<U18'), array([['S11', 'Purchases 1.55011271', 'frame_261.jpg']], dtype='<U20'), array([['S11', 'Greeting.60457274', 'frame_321.jpg']], dtype='<U17'), array([['S1', 'SittingDown.58860488', 'frame_701.jpg']], dtype='<U20'), array([['S5', 'Directions 2.55011271', 'frame_1721.jpg']], dtype='<U21'), array([['S5', 'Phoning.55011271', 'frame_1581.jpg']], dtype='<U16'), array([['S9', 'Purchases 1.55011271', 'frame_101.jpg']], dtype='<U20'), array([['S7', 'Smoking 1.58860488', 'frame_181.jpg']], dtype='<U18'), array([['S5', 'Walking.54138969', 'frame_2001.jpg']], dtype='<U16'), array([['S7', 'SittingDown.58860488', 'frame_201.jpg']], dtype='<U20'), array([['S5', 'Sitting 1.54138969', 'frame_2701.jpg']], dtype='<U18'), array([['S9', 'Smoking.60457274', 'frame_1021.jpg']], dtype='<U16'), array([['S5', 'Greeting 2.58860488', 'frame_241.jpg']], dtype='<U19'), array([['S1', 'TakingPhoto.55011271', 'frame_961.jpg']], dtype='<U20'), array([['S1', 'Discussion.58860488', 'frame_2041.jpg']], dtype='<U19'), array([['S7', 'SittingDown.58860488', 'frame_181.jpg']], dtype='<U20'), array([['S11', 'Purchases.60457274', 'frame_981.jpg']], dtype='<U18'), array([['S7', 'Smoking.60457274', 'frame_2421.jpg']], dtype='<U16'), array([['S5', 'WalkDog.54138969', 'frame_1981.jpg']], dtype='<U16'), array([['S5', 'SittingDown 1.55011271', 'frame_321.jpg']], dtype='<U22'), array([['S5', 'Sitting.58860488', 'frame_3341.jpg']], dtype='<U16'), array([['S11', 'Phoning 2.60457274', 'frame_2021.jpg']], dtype='<U18'), array([['S11', 'SittingDown.58860488', 'frame_1381.jpg']], dtype='<U20'), array([['S9', 'Photo.60457274', 'frame_1801.jpg']], dtype='<U14'), array([['S1', 'Smoking.55011271', 'frame_361.jpg']], dtype='<U16'), array([['S5', 'SittingDown 1.60457274', 'frame_2061.jpg']], dtype='<U22'), array([['S7', 'Photo 1.60457274', 'frame_301.jpg']], dtype='<U16'), array([['S5', 'WalkDog.55011271', 'frame_2061.jpg']], dtype='<U16'), array([['S5', 'Photo.60457274', 'frame_921.jpg']], dtype='<U14'), array([['S7', 'Posing.55011271', 'frame_81.jpg']], dtype='<U15'), array([['S7', 'Discussion 1.55011271', 'frame_4161.jpg']], dtype='<U21'), array([['S11', 'Walking.58860488', 'frame_621.jpg']], dtype='<U16'), array([['S7', 'SittingDown.60457274', 'frame_3781.jpg']], dtype='<U20'), array([['S9', 'Smoking 1.55011271', 'frame_1441.jpg']], dtype='<U18'), array([['S11', 'Discussion 1.54138969', 'frame_1561.jpg']], dtype='<U21'), array([['S7', 'Walking 1.60457274', 'frame_1661.jpg']], dtype='<U18'), array([['S1', 'TakingPhoto 1.55011271', 'frame_581.jpg']], dtype='<U22'), array([['S1', 'Walking 1.60457274', 'frame_2221.jpg']], dtype='<U18'), array([['S11', 'Posing.60457274', 'frame_501.jpg']], dtype='<U15'), array([['S7', 'SittingDown 1.60457274', 'frame_1881.jpg']], dtype='<U22'), array([['S5', 'SittingDown 1.58860488', 'frame_81.jpg']], dtype='<U22'), array([['S7', 'Sitting.60457274', 'frame_141.jpg']], dtype='<U16'), array([['S5', 'Greeting 2.55011271', 'frame_1481.jpg']], dtype='<U19'), array([['S7', 'Phoning 2.55011271', 'frame_4161.jpg']], dtype='<U18'), array([['S7', 'Waiting 2.55011271', 'frame_301.jpg']], dtype='<U18'), array([['S5', 'Photo 2.54138969', 'frame_1121.jpg']], dtype='<U16'), array([['S7', 'SittingDown 1.55011271', 'frame_3601.jpg']], dtype='<U22'), array([['S5', 'Purchases 1.55011271', 'frame_1601.jpg']], dtype='<U20'), array([['S7', 'WalkTogether 1.55011271', 'frame_1481.jpg']], dtype='<U23'), array([['S9', 'Eating.55011271', 'frame_981.jpg']], dtype='<U15'), array([['S9', 'Waiting 1.60457274', 'frame_1461.jpg']], dtype='<U18'), array([['S5', 'Greeting 2.55011271', 'frame_2901.jpg']], dtype='<U19'), array([['S5', 'Discussion 3.58860488', 'frame_4381.jpg']], dtype='<U21'), array([['S5', 'WalkTogether 1.54138969', 'frame_721.jpg']], dtype='<U23'), array([['S5', 'WalkTogether.60457274', 'frame_2681.jpg']], dtype='<U21'), array([['S9', 'Posing.58860488', 'frame_1581.jpg']], dtype='<U15'), array([['S9', 'Sitting.55011271', 'frame_581.jpg']], dtype='<U16'), array([['S7', 'Walking 1.60457274', 'frame_1221.jpg']], dtype='<U18'), array([['S5', 'Greeting 1.60457274', 'frame_1061.jpg']], dtype='<U19'), array([['S11', 'Photo.60457274', 'frame_1061.jpg']], dtype='<U14'), array([['S7', 'Discussion.58860488', 'frame_201.jpg']], dtype='<U19'), array([['S1', 'Eating 2.55011271', 'frame_301.jpg']], dtype='<U17'), array([['S9', 'Posing 1.55011271', 'frame_1841.jpg']], dtype='<U17'), array([['S9', 'Sitting 1.60457274', 'frame_581.jpg']], dtype='<U18'), array([['S7', 'Waiting 2.55011271', 'frame_1561.jpg']], dtype='<U18'), array([['S7', 'Discussion.55011271', 'frame_1841.jpg']], dtype='<U19'), array([['S11', 'WalkDog.54138969', 'frame_1041.jpg']], dtype='<U16'), array([['S9', 'Photo.58860488', 'frame_941.jpg']], dtype='<U14'), array([['S7', 'Eating 1.58860488', 'frame_2961.jpg']], dtype='<U17'), array([['S1', 'Eating.58860488', 'frame_261.jpg']], dtype='<U15'), array([['S9', 'WalkDog.54138969', 'frame_1341.jpg']], dtype='<U16'), array([['S1', 'SittingDown.58860488', 'frame_1381.jpg']], dtype='<U20'), array([['S9', 'Smoking.55011271', 'frame_1261.jpg']], dtype='<U16'), array([['S9', 'Purchases 1.58860488', 'frame_681.jpg']], dtype='<U20'), array([['S11', 'Photo 1.60457274', 'frame_181.jpg']], dtype='<U16'), array([['S5', 'Discussion 3.60457274', 'frame_2361.jpg']], dtype='<U21'), array([['S9', 'Discussion 2.58860488', 'frame_1581.jpg']], dtype='<U21'), array([['S9', 'SittingDown.58860488', 'frame_441.jpg']], dtype='<U20'), array([['S7', 'WalkDog.55011271', 'frame_921.jpg']], dtype='<U16'), array([['S7', 'Posing.60457274', 'frame_2321.jpg']], dtype='<U15'), array([['S1', 'Posing.60457274', 'frame_221.jpg']], dtype='<U15'), array([['S5', 'SittingDown 1.60457274', 'frame_2641.jpg']], dtype='<U22'), array([['S5', 'SittingDown.60457274', 'frame_981.jpg']], dtype='<U20'), array([['S1', 'Phoning 1.55011271', 'frame_821.jpg']], dtype='<U18'), array([['S7', 'Photo.58860488', 'frame_121.jpg']], dtype='<U14'), array([['S1', 'Phoning.55011271', 'frame_1961.jpg']], dtype='<U16'), array([['S5', 'Smoking 1.60457274', 'frame_1001.jpg']], dtype='<U18'), array([['S9', 'Waiting 1.54138969', 'frame_941.jpg']], dtype='<U18'), array([['S9', 'WalkTogether 1.58860488', 'frame_1521.jpg']], dtype='<U23'), array([['S5', 'Greeting 2.54138969', 'frame_281.jpg']], dtype='<U19'), array([['S11', 'Sitting.60457274', 'frame_381.jpg']], dtype='<U16'), array([['S5', 'Sitting.60457274', 'frame_1321.jpg']], dtype='<U16'), array([['S11', 'Waiting.60457274', 'frame_2161.jpg']], dtype='<U16'), array([['S7', 'Eating.58860488', 'frame_2221.jpg']], dtype='<U15'), array([['S7', 'Walking 1.54138969', 'frame_1861.jpg']], dtype='<U18'), array([['S9', 'Greeting 1.60457274', 'frame_801.jpg']], dtype='<U19'), array([['S7', 'Waiting 2.58860488', 'frame_3041.jpg']], dtype='<U18'), array([['S5', 'SittingDown.58860488', 'frame_1401.jpg']], dtype='<U20'), array([['S11', 'Sitting 1.55011271', 'frame_1061.jpg']], dtype='<U18'), array([['S11', 'Purchases 1.55011271', 'frame_381.jpg']], dtype='<U20'), array([['S1', 'Phoning 1.55011271', 'frame_561.jpg']], dtype='<U18'), array([['S7', 'Purchases 1.58860488', 'frame_121.jpg']], dtype='<U20'), array([['S1', 'Phoning 1.58860488', 'frame_2141.jpg']], dtype='<U18'), array([['S11', 'Smoking 2.54138969', 'frame_2121.jpg']], dtype='<U18'), array([['S7', 'Phoning.55011271', 'frame_3281.jpg']], dtype='<U16'), array([['S7', 'Photo.54138969', 'frame_1661.jpg']], dtype='<U14'), array([['S5', 'Phoning 1.54138969', 'frame_41.jpg']], dtype='<U18'), array([['S7', 'Photo 1.55011271', 'frame_321.jpg']], dtype='<U16'), array([['S11', 'Sitting.60457274', 'frame_441.jpg']], dtype='<U16'), array([['S7', 'Discussion.54138969', 'frame_3761.jpg']], dtype='<U19'), array([['S11', 'SittingDown 1.58860488', 'frame_481.jpg']], dtype='<U22'), array([['S9', 'Walking.54138969', 'frame_441.jpg']], dtype='<U16'), array([['S7', 'Smoking 1.55011271', 'frame_4381.jpg']], dtype='<U18'), array([['S7', 'Discussion 1.58860488', 'frame_541.jpg']], dtype='<U21'), array([['S5', 'WalkTogether 1.55011271', 'frame_1341.jpg']], dtype='<U23'), array([['S9', 'WalkDog 1.55011271', 'frame_1201.jpg']], dtype='<U18'), array([['S5', 'Phoning 1.55011271', 'frame_481.jpg']], dtype='<U18'), array([['S11', 'SittingDown.58860488', 'frame_1661.jpg']], dtype='<U20'), array([['S1', 'Smoking.58860488', 'frame_1541.jpg']], dtype='<U16'), array([['S9', 'Walking 1.58860488', 'frame_2101.jpg']], dtype='<U18'), array([['S7', 'Discussion 1.60457274', 'frame_2661.jpg']], dtype='<U21'), array([['S1', 'Directions.54138969', 'frame_301.jpg']], dtype='<U19'), array([['S1', 'Posing.54138969', 'frame_681.jpg']], dtype='<U15'), array([['S5', 'Sitting 1.54138969', 'frame_301.jpg']], dtype='<U18'), array([['S1', 'Discussion 1.60457274', 'frame_1321.jpg']], dtype='<U21'), array([['S9', 'Smoking 1.55011271', 'frame_2061.jpg']], dtype='<U18'), array([['S7', 'Walking 2.55011271', 'frame_3061.jpg']], dtype='<U18'), array([['S9', 'Walking 1.60457274', 'frame_781.jpg']], dtype='<U18'), array([['S9', 'WalkDog 1.60457274', 'frame_701.jpg']], dtype='<U18'), array([['S5', 'Posing 1.60457274', 'frame_2121.jpg']], dtype='<U17'), array([['S5', 'Walking.55011271', 'frame_1781.jpg']], dtype='<U16'), array([['S9', 'WalkTogether.58860488', 'frame_41.jpg']], dtype='<U21'), array([['S5', 'Posing 1.58860488', 'frame_1881.jpg']], dtype='<U17'), array([['S7', 'WalkTogether.54138969', 'frame_1461.jpg']], dtype='<U21'), array([['S7', 'Greeting 1.60457274', 'frame_1181.jpg']], dtype='<U19'), array([['S1', 'Discussion.54138969', 'frame_1.jpg']], dtype='<U19'), array([['S1', 'WalkTogether.60457274', 'frame_421.jpg']], dtype='<U21'), array([['S1', 'Discussion 1.55011271', 'frame_2621.jpg']], dtype='<U21'), array([['S11', 'WalkTogether 1.54138969', 'frame_101.jpg']], dtype='<U23'), array([['S11', 'Sitting 1.54138969', 'frame_1501.jpg']], dtype='<U18'), array([['S5', 'Smoking.58860488', 'frame_3261.jpg']], dtype='<U16'), array([['S1', 'SittingDown 2.60457274', 'frame_81.jpg']], dtype='<U22'), array([['S9', 'SittingDown 1.60457274', 'frame_481.jpg']], dtype='<U22'), array([['S1', 'Smoking 1.58860488', 'frame_641.jpg']], dtype='<U18'), array([['S5', 'Sitting.55011271', 'frame_3181.jpg']], dtype='<U16'), array([['S11', 'Walking.55011271', 'frame_501.jpg']], dtype='<U16'), array([['S7', 'Sitting.58860488', 'frame_2501.jpg']], dtype='<U16'), array([['S11', 'Greeting.54138969', 'frame_1561.jpg']], dtype='<U17'), array([['S11', 'WalkTogether 1.60457274', 'frame_141.jpg']], dtype='<U23'), array([['S5', 'Eating 1.60457274', 'frame_2781.jpg']], dtype='<U17'), array([['S7', 'WalkTogether.60457274', 'frame_901.jpg']], dtype='<U21'), array([['S5', 'Greeting 1.54138969', 'frame_1121.jpg']], dtype='<U19'), array([['S7', 'WalkDog.58860488', 'frame_2701.jpg']], dtype='<U16'), array([['S7', 'Discussion 1.60457274', 'frame_161.jpg']], dtype='<U21'), array([['S7', 'Walking 2.60457274', 'frame_3321.jpg']], dtype='<U18'), array([['S9', 'Waiting.60457274', 'frame_2221.jpg']], dtype='<U16'), array([['S5', 'Smoking 1.55011271', 'frame_2961.jpg']], dtype='<U18'), array([['S1', 'Directions 1.55011271', 'frame_661.jpg']], dtype='<U21'), array([['S5', 'Directions 2.60457274', 'frame_621.jpg']], dtype='<U21'), array([['S1', 'Walking 1.55011271', 'frame_541.jpg']], dtype='<U18'), array([['S9', 'Waiting.54138969', 'frame_1041.jpg']], dtype='<U16'), array([['S5', 'Purchases 1.60457274', 'frame_1461.jpg']], dtype='<U20'), array([['S7', 'Walking 2.60457274', 'frame_2361.jpg']], dtype='<U18'), array([['S9', 'WalkDog.58860488', 'frame_1681.jpg']], dtype='<U16'), array([['S9', 'Discussion 2.58860488', 'frame_401.jpg']], dtype='<U21'), array([['S7', 'Walking 2.55011271', 'frame_361.jpg']], dtype='<U18'), array([['S5', 'SittingDown 1.60457274', 'frame_3741.jpg']], dtype='<U22'), array([['S5', 'Photo.58860488', 'frame_1581.jpg']], dtype='<U14'), array([['S9', 'Smoking 1.54138969', 'frame_2161.jpg']], dtype='<U18'), array([['S5', 'SittingDown 1.54138969', 'frame_2441.jpg']], dtype='<U22'), array([['S5', 'Discussion 3.60457274', 'frame_2881.jpg']], dtype='<U21'), array([['S7', 'Waiting 1.60457274', 'frame_1861.jpg']], dtype='<U18'), array([['S7', 'SittingDown 1.60457274', 'frame_3021.jpg']], dtype='<U22'), array([['S5', 'Purchases.54138969', 'frame_1601.jpg']], dtype='<U18'), array([['S9', 'Eating 1.54138969', 'frame_1581.jpg']], dtype='<U17'), array([['S7', 'Walking 2.60457274', 'frame_1661.jpg']], dtype='<U18'), array([['S5', 'Posing.54138969', 'frame_1161.jpg']], dtype='<U15'), array([['S1', 'TakingPhoto 1.58860488', 'frame_601.jpg']], dtype='<U22'), array([['S11', 'SittingDown.58860488', 'frame_141.jpg']], dtype='<U20'), array([['S7', 'Smoking.54138969', 'frame_4661.jpg']], dtype='<U16'), array([['S5', 'SittingDown 1.55011271', 'frame_2081.jpg']], dtype='<U22'), array([['S5', 'Waiting 2.54138969', 'frame_4221.jpg']], dtype='<U18'), array([['S5', 'Smoking 1.60457274', 'frame_381.jpg']], dtype='<U18'), array([['S11', 'Greeting.60457274', 'frame_501.jpg']], dtype='<U17'), array([['S5', 'SittingDown.60457274', 'frame_3921.jpg']], dtype='<U20'), array([['S5', 'Discussion 3.54138969', 'frame_1261.jpg']], dtype='<U21'), array([['S1', 'Greeting 1.54138969', 'frame_501.jpg']], dtype='<U19'), array([['S5', 'Sitting 1.54138969', 'frame_3781.jpg']], dtype='<U18'), array([['S7', 'WalkDog.54138969', 'frame_1861.jpg']], dtype='<U16'), array([['S7', 'WalkTogether.54138969', 'frame_2621.jpg']], dtype='<U21'), array([['S9', 'Phoning.55011271', 'frame_1381.jpg']], dtype='<U16'), array([['S7', 'SittingDown 1.55011271', 'frame_5201.jpg']], dtype='<U22'), array([['S1', 'Smoking.54138969', 'frame_1181.jpg']], dtype='<U16'), array([['S9', 'Posing 1.60457274', 'frame_681.jpg']], dtype='<U17'), array([['S7', 'Discussion.60457274', 'frame_2481.jpg']], dtype='<U19'), array([['S7', 'SittingDown.58860488', 'frame_1661.jpg']], dtype='<U20'), array([['S7', 'Greeting.58860488', 'frame_801.jpg']], dtype='<U17'), array([['S5', 'SittingDown.60457274', 'frame_1541.jpg']], dtype='<U20'), array([['S1', 'WalkingDog 1.55011271', 'frame_541.jpg']], dtype='<U21'), array([['S1', 'Sitting 1.60457274', 'frame_3041.jpg']], dtype='<U18'), array([['S5', 'Smoking 1.60457274', 'frame_2461.jpg']], dtype='<U18'), array([['S5', 'Photo 2.54138969', 'frame_1961.jpg']], dtype='<U16'), array([['S9', 'Discussion 1.58860488', 'frame_441.jpg']], dtype='<U21'), array([['S5', 'SittingDown.60457274', 'frame_3761.jpg']], dtype='<U20'), array([['S5', 'Directions 2.58860488', 'frame_2021.jpg']], dtype='<U21'), array([['S1', 'Discussion 1.54138969', 'frame_1961.jpg']], dtype='<U21'), array([['S5', 'Sitting 1.60457274', 'frame_2741.jpg']], dtype='<U18'), array([['S9', 'SittingDown.60457274', 'frame_861.jpg']], dtype='<U20'), array([['S1', 'SittingDown.54138969', 'frame_1741.jpg']], dtype='<U20'), array([['S5', 'SittingDown 1.55011271', 'frame_2501.jpg']], dtype='<U22'), array([['S7', 'SittingDown.54138969', 'frame_3001.jpg']], dtype='<U20'), array([['S9', 'Purchases 1.55011271', 'frame_601.jpg']], dtype='<U20'), array([['S9', 'Waiting.54138969', 'frame_2241.jpg']], dtype='<U16'), array([['S7', 'Sitting.60457274', 'frame_1901.jpg']], dtype='<U16'), array([['S11', 'Waiting 1.54138969', 'frame_981.jpg']], dtype='<U18'), array([['S5', 'Waiting 1.58860488', 'frame_1761.jpg']], dtype='<U18'), array([['S7', 'Smoking 1.60457274', 'frame_241.jpg']], dtype='<U18'), array([['S11', 'Sitting 1.58860488', 'frame_1641.jpg']], dtype='<U18'), array([['S7', 'Sitting.54138969', 'frame_1181.jpg']], dtype='<U16'), array([['S1', 'SittingDown.55011271', 'frame_901.jpg']], dtype='<U20'), array([['S9', 'Greeting.60457274', 'frame_1.jpg']], dtype='<U17'), array([['S7', 'WalkDog.60457274', 'frame_2461.jpg']], dtype='<U16'), array([['S7', 'Eating 1.60457274', 'frame_2941.jpg']], dtype='<U17'), array([['S11', 'Smoking.55011271', 'frame_1481.jpg']], dtype='<U16'), array([['S5', 'Photo 2.58860488', 'frame_621.jpg']], dtype='<U16'), array([['S1', 'Eating.58860488', 'frame_221.jpg']], dtype='<U15'), array([['S7', 'Directions.55011271', 'frame_1821.jpg']], dtype='<U19'), array([['S1', 'Posing 1.60457274', 'frame_941.jpg']], dtype='<U17'), array([['S1', 'Waiting.58860488', 'frame_141.jpg']], dtype='<U16'), array([['S7', 'Discussion 1.58860488', 'frame_2301.jpg']], dtype='<U21'), array([['S5', 'Directions 2.60457274', 'frame_1381.jpg']], dtype='<U21'), array([['S7', 'Phoning.60457274', 'frame_3441.jpg']], dtype='<U16'), array([['S5', 'Sitting 1.55011271', 'frame_1401.jpg']], dtype='<U18'), array([['S9', 'Photo 1.55011271', 'frame_1361.jpg']], dtype='<U16'), array([['S5', 'Directions 2.60457274', 'frame_81.jpg']], dtype='<U21'), array([['S11', 'Waiting.60457274', 'frame_101.jpg']], dtype='<U16'), array([['S11', 'Greeting.55011271', 'frame_1321.jpg']], dtype='<U17'), array([['S9', 'Waiting.60457274', 'frame_1181.jpg']], dtype='<U16'), array([['S9', 'Discussion 1.54138969', 'frame_2001.jpg']], dtype='<U21'), array([['S11', 'Posing.55011271', 'frame_1.jpg']], dtype='<U15'), array([['S1', 'Eating.54138969', 'frame_441.jpg']], dtype='<U15'), array([['S9', 'WalkDog 1.54138969', 'frame_761.jpg']], dtype='<U18'), array([['S11', 'Discussion 1.54138969', 'frame_1581.jpg']], dtype='<U21'), array([['S1', 'Smoking.55011271', 'frame_821.jpg']], dtype='<U16'), array([['S5', 'Smoking.60457274', 'frame_601.jpg']], dtype='<U16'), array([['S9', 'Directions.55011271', 'frame_1381.jpg']], dtype='<U19'), array([['S11', 'Photo.54138969', 'frame_1001.jpg']], dtype='<U14'), array([['S11', 'Greeting 2.60457274', 'frame_1181.jpg']], dtype='<U19'), array([['S7', 'Sitting.58860488', 'frame_1401.jpg']], dtype='<U16'), array([['S9', 'Sitting 1.60457274', 'frame_2061.jpg']], dtype='<U18'), array([['S9', 'WalkDog.54138969', 'frame_2021.jpg']], dtype='<U16'), array([['S7', 'Photo 1.54138969', 'frame_121.jpg']], dtype='<U16'), array([['S5', 'Posing.60457274', 'frame_441.jpg']], dtype='<U15'), array([['S11', 'Posing 1.54138969', 'frame_461.jpg']], dtype='<U17'), array([['S5', 'WalkTogether 1.60457274', 'frame_2861.jpg']], dtype='<U23'), array([['S5', 'Photo 2.55011271', 'frame_2241.jpg']], dtype='<U16'), array([['S9', 'Phoning.58860488', 'frame_1341.jpg']], dtype='<U16'), array([['S9', 'WalkDog 1.60457274', 'frame_2201.jpg']], dtype='<U18'), array([['S1', 'Walking 1.60457274', 'frame_921.jpg']], dtype='<U18'), array([['S11', 'Phoning 2.55011271', 'frame_461.jpg']], dtype='<U18'), array([['S9', 'Eating.58860488', 'frame_341.jpg']], dtype='<U15'), array([['S11', 'Phoning 3.58860488', 'frame_1561.jpg']], dtype='<U18'), array([['S9', 'Discussion 2.54138969', 'frame_1321.jpg']], dtype='<U21'), array([['S7', 'SittingDown 1.55011271', 'frame_5341.jpg']], dtype='<U22'), array([['S1', 'Smoking 1.54138969', 'frame_2281.jpg']], dtype='<U18'), array([['S7', 'Walking 2.54138969', 'frame_2341.jpg']], dtype='<U18'), array([['S5', 'Eating 1.54138969', 'frame_261.jpg']], dtype='<U17'), array([['S11', 'Smoking.55011271', 'frame_1981.jpg']], dtype='<U16'), array([['S7', 'Discussion 1.58860488', 'frame_2801.jpg']], dtype='<U21'), array([['S5', 'Purchases.55011271', 'frame_2861.jpg']], dtype='<U18'), array([['S5', 'Sitting 1.54138969', 'frame_2481.jpg']], dtype='<U18'), array([['S7', 'Smoking.55011271', 'frame_121.jpg']], dtype='<U16'), array([['S5', 'Posing.60457274', 'frame_1321.jpg']], dtype='<U15'), array([['S7', 'Sitting 1.55011271', 'frame_4201.jpg']], dtype='<U18'), array([['S5', 'Discussion 2.55011271', 'frame_5961.jpg']], dtype='<U21'), array([['S1', 'WalkTogether 1.60457274', 'frame_781.jpg']], dtype='<U23'), array([['S1', 'WalkTogether.55011271', 'frame_241.jpg']], dtype='<U21'), array([['S11', 'Phoning 2.54138969', 'frame_1101.jpg']], dtype='<U18'), array([['S5', 'Phoning 1.60457274', 'frame_1901.jpg']], dtype='<U18'), array([['S1', 'Discussion 1.54138969', 'frame_621.jpg']], dtype='<U21'), array([['S9', 'SittingDown.54138969', 'frame_541.jpg']], dtype='<U20'), array([['S7', 'Eating.58860488', 'frame_1761.jpg']], dtype='<U15'), array([['S5', 'Greeting 1.55011271', 'frame_281.jpg']], dtype='<U19'), array([['S7', 'Waiting 1.54138969', 'frame_2681.jpg']], dtype='<U18'), array([['S1', 'TakingPhoto 1.60457274', 'frame_861.jpg']], dtype='<U22'), array([['S7', 'Smoking.54138969', 'frame_2741.jpg']], dtype='<U16'), array([['S7', 'Discussion 1.60457274', 'frame_2841.jpg']], dtype='<U21'), array([['S7', 'Purchases.60457274', 'frame_1261.jpg']], dtype='<U18'), array([['S1', 'Walking.60457274', 'frame_681.jpg']], dtype='<U16'), array([['S9', 'WalkDog 1.60457274', 'frame_201.jpg']], dtype='<U18'), array([['S1', 'Walking 1.60457274', 'frame_1221.jpg']], dtype='<U18'), array([['S11', 'SittingDown 1.54138969', 'frame_941.jpg']], dtype='<U22'), array([['S1', 'Posing.55011271', 'frame_801.jpg']], dtype='<U15'), array([['S5', 'Phoning.54138969', 'frame_661.jpg']], dtype='<U16'), array([['S1', 'Phoning.58860488', 'frame_2261.jpg']], dtype='<U16'), array([['S1', 'Phoning 1.58860488', 'frame_2101.jpg']], dtype='<U18'), array([['S11', 'Smoking 2.55011271', 'frame_961.jpg']], dtype='<U18'), array([['S7', 'Sitting 1.54138969', 'frame_3861.jpg']], dtype='<U18'), array([['S9', 'Discussion 1.55011271', 'frame_1121.jpg']], dtype='<U21'), array([['S5', 'Greeting 1.55011271', 'frame_1421.jpg']], dtype='<U19'), array([['S11', 'Smoking 2.54138969', 'frame_701.jpg']], dtype='<U18'), array([['S9', 'Sitting.55011271', 'frame_1221.jpg']], dtype='<U16'), array([['S9', 'Directions 1.55011271', 'frame_141.jpg']], dtype='<U21'), array([['S1', 'Walking 1.60457274', 'frame_2061.jpg']], dtype='<U18'), array([['S7', 'SittingDown 1.60457274', 'frame_881.jpg']], dtype='<U22'), array([['S11', 'Walking.58860488', 'frame_681.jpg']], dtype='<U16'), array([['S5', 'SittingDown 1.55011271', 'frame_1181.jpg']], dtype='<U22'), array([['S9', 'Walking.60457274', 'frame_241.jpg']], dtype='<U16'), array([['S9', 'WalkTogether.54138969', 'frame_1181.jpg']], dtype='<U21'), array([['S5', 'Sitting 1.60457274', 'frame_2361.jpg']], dtype='<U18'), array([['S9', 'Directions 1.58860488', 'frame_2161.jpg']], dtype='<U21'), array([['S9', 'Discussion 1.58860488', 'frame_1081.jpg']], dtype='<U21'), array([['S5', 'WalkTogether 1.58860488', 'frame_541.jpg']], dtype='<U23'), array([['S5', 'Smoking 1.58860488', 'frame_3121.jpg']], dtype='<U18'), array([['S7', 'WalkDog.60457274', 'frame_401.jpg']], dtype='<U16'), array([['S9', 'SittingDown.58860488', 'frame_981.jpg']], dtype='<U20'), array([['S9', 'Directions.54138969', 'frame_1441.jpg']], dtype='<U19'), array([['S7', 'Sitting 1.55011271', 'frame_461.jpg']], dtype='<U18'), array([['S11', 'Greeting.55011271', 'frame_1521.jpg']], dtype='<U17'), array([['S9', 'WalkTogether.54138969', 'frame_1041.jpg']], dtype='<U21'), array([['S7', 'Walking 1.54138969', 'frame_401.jpg']], dtype='<U18'), array([['S5', 'SittingDown 1.60457274', 'frame_3841.jpg']], dtype='<U22'), array([['S7', 'Waiting 1.58860488', 'frame_1261.jpg']], dtype='<U18'), array([['S9', 'Waiting.55011271', 'frame_121.jpg']], dtype='<U16'), array([['S11', 'Sitting.55011271', 'frame_1881.jpg']], dtype='<U16'), array([['S5', 'SittingDown.58860488', 'frame_3001.jpg']], dtype='<U20'), array([['S7', 'Discussion.60457274', 'frame_1221.jpg']], dtype='<U19'), array([['S5', 'Walking 1.58860488', 'frame_2381.jpg']], dtype='<U18'), array([['S1', 'Smoking 1.58860488', 'frame_1761.jpg']], dtype='<U18'), array([['S1', 'Directions.55011271', 'frame_1561.jpg']], dtype='<U19'), array([['S7', 'Purchases.58860488', 'frame_401.jpg']], dtype='<U18'), array([['S9', 'Discussion 2.54138969', 'frame_181.jpg']], dtype='<U21'), array([['S11', 'Sitting.54138969', 'frame_701.jpg']], dtype='<U16'), array([['S1', 'Discussion 1.60457274', 'frame_3061.jpg']], dtype='<U21'), array([['S5', 'Smoking 1.60457274', 'frame_721.jpg']], dtype='<U18'), array([['S7', 'Posing.58860488', 'frame_1561.jpg']], dtype='<U15'), array([['S5', 'SittingDown 1.54138969', 'frame_3901.jpg']], dtype='<U22'), array([['S1', 'WalkingDog.55011271', 'frame_121.jpg']], dtype='<U19'), array([['S5', 'Phoning 1.58860488', 'frame_3261.jpg']], dtype='<U18'), array([['S9', 'Walking 1.55011271', 'frame_281.jpg']], dtype='<U18'), array([['S5', 'Sitting 1.60457274', 'frame_1881.jpg']], dtype='<U18'), array([['S7', 'Eating 1.55011271', 'frame_3721.jpg']], dtype='<U17'), array([['S7', 'Smoking.58860488', 'frame_3901.jpg']], dtype='<U16'), array([['S7', 'Photo 1.54138969', 'frame_281.jpg']], dtype='<U16'), array([['S7', 'SittingDown 1.58860488', 'frame_2061.jpg']], dtype='<U22'), array([['S11', 'Photo.60457274', 'frame_641.jpg']], dtype='<U14'), array([['S7', 'Waiting 2.54138969', 'frame_781.jpg']], dtype='<U18'), array([['S5', 'SittingDown.60457274', 'frame_4761.jpg']], dtype='<U20'), array([['S11', 'Waiting 1.58860488', 'frame_2141.jpg']], dtype='<U18'), array([['S1', 'Directions 1.60457274', 'frame_921.jpg']], dtype='<U21'), array([['S1', 'Phoning 1.54138969', 'frame_941.jpg']], dtype='<U18'), array([['S11', 'Sitting 1.60457274', 'frame_1181.jpg']], dtype='<U18'), array([['S1', 'WalkingDog 1.55011271', 'frame_1041.jpg']], dtype='<U21'), array([['S5', 'Sitting 1.54138969', 'frame_681.jpg']], dtype='<U18'), array([['S7', 'Walking 1.60457274', 'frame_2421.jpg']], dtype='<U18'), array([['S5', 'Purchases.55011271', 'frame_3061.jpg']], dtype='<U18'), array([['S9', 'SittingDown.60457274', 'frame_761.jpg']], dtype='<U20'), array([['S1', 'Phoning.54138969', 'frame_1301.jpg']], dtype='<U16'), array([['S5', 'WalkTogether.58860488', 'frame_2901.jpg']], dtype='<U21'), array([['S5', 'Phoning 1.60457274', 'frame_2881.jpg']], dtype='<U18'), array([['S5', 'Sitting.54138969', 'frame_201.jpg']], dtype='<U16'), array([['S7', 'WalkTogether 1.60457274', 'frame_41.jpg']], dtype='<U23'), array([['S7', 'Greeting 1.60457274', 'frame_1281.jpg']], dtype='<U19'), array([['S9', 'Greeting 1.54138969', 'frame_501.jpg']], dtype='<U19'), array([['S9', 'Posing 1.55011271', 'frame_261.jpg']], dtype='<U17'), array([['S7', 'Waiting 1.58860488', 'frame_2421.jpg']], dtype='<U18'), array([['S5', 'WalkTogether 1.54138969', 'frame_141.jpg']], dtype='<U23'), array([['S7', 'Discussion.58860488', 'frame_3321.jpg']], dtype='<U19'), array([['S9', 'Smoking 1.60457274', 'frame_521.jpg']], dtype='<U18'), array([['S7', 'Sitting 1.55011271', 'frame_361.jpg']], dtype='<U18'), array([['S7', 'Smoking.54138969', 'frame_1401.jpg']], dtype='<U16'), array([['S9', 'Walking 1.54138969', 'frame_1261.jpg']], dtype='<U18'), array([['S7', 'Eating 1.54138969', 'frame_1461.jpg']], dtype='<U17'), array([['S7', 'Phoning.54138969', 'frame_2081.jpg']], dtype='<U16'), array([['S11', 'Purchases.55011271', 'frame_861.jpg']], dtype='<U18'), array([['S5', 'WalkTogether 1.54138969', 'frame_1561.jpg']], dtype='<U23'), array([['S5', 'Eating 1.55011271', 'frame_2181.jpg']], dtype='<U17'), array([['S11', 'WalkTogether.60457274', 'frame_181.jpg']], dtype='<U21'), array([['S1', 'Walking 1.55011271', 'frame_901.jpg']], dtype='<U18'), array([['S1', 'Waiting 1.60457274', 'frame_481.jpg']], dtype='<U18'), array([['S5', 'SittingDown 1.58860488', 'frame_541.jpg']], dtype='<U22'), array([['S7', 'Phoning 2.60457274', 'frame_221.jpg']], dtype='<U18'), array([['S5', 'Posing 1.58860488', 'frame_2081.jpg']], dtype='<U17'), array([['S11', 'Sitting.58860488', 'frame_1521.jpg']], dtype='<U16'), array([['S1', 'Discussion.55011271', 'frame_2221.jpg']], dtype='<U19'), array([['S1', 'Discussion 1.60457274', 'frame_101.jpg']], dtype='<U21'), array([['S1', 'Discussion 1.55011271', 'frame_681.jpg']], dtype='<U21'), array([['S1', 'Eating 2.54138969', 'frame_2101.jpg']], dtype='<U17'), array([['S5', 'Eating 1.60457274', 'frame_761.jpg']], dtype='<U17'), array([['S5', 'Waiting 1.58860488', 'frame_4301.jpg']], dtype='<U18'), array([['S5', 'Smoking 1.55011271', 'frame_3121.jpg']], dtype='<U18'), array([['S11', 'Posing.58860488', 'frame_1.jpg']], dtype='<U15'), array([['S9', 'WalkTogether.54138969', 'frame_201.jpg']], dtype='<U21'), array([['S5', 'WalkTogether.60457274', 'frame_401.jpg']], dtype='<U21'), array([['S9', 'Posing 1.60457274', 'frame_1481.jpg']], dtype='<U17'), array([['S7', 'WalkDog.60457274', 'frame_1541.jpg']], dtype='<U16'), array([['S9', 'Directions.58860488', 'frame_1741.jpg']], dtype='<U19'), array([['S7', 'Discussion.58860488', 'frame_441.jpg']], dtype='<U19'), array([['S7', 'Posing 1.54138969', 'frame_1541.jpg']], dtype='<U17'), array([['S5', 'Eating.54138969', 'frame_1821.jpg']], dtype='<U15'), array([['S5', 'WalkDog 1.58860488', 'frame_381.jpg']], dtype='<U18'), array([['S7', 'Posing 1.58860488', 'frame_1561.jpg']], dtype='<U17'), array([['S11', 'WalkDog 1.60457274', 'frame_181.jpg']], dtype='<U18'), array([['S9', 'Walking.60457274', 'frame_1381.jpg']], dtype='<U16'), array([['S7', 'SittingDown 1.58860488', 'frame_2221.jpg']], dtype='<U22'), array([['S7', 'WalkTogether 1.55011271', 'frame_1941.jpg']], dtype='<U23'), array([['S1', 'WalkingDog.58860488', 'frame_21.jpg']], dtype='<U19'), array([['S5', 'WalkTogether.60457274', 'frame_521.jpg']], dtype='<U21'), array([['S11', 'Walking 1.58860488', 'frame_341.jpg']], dtype='<U18'), array([['S11', 'Eating 1.54138969', 'frame_1521.jpg']], dtype='<U17'), array([['S5', 'Smoking 1.60457274', 'frame_141.jpg']], dtype='<U18'), array([['S5', 'Discussion 2.55011271', 'frame_3821.jpg']], dtype='<U21'), array([['S9', 'WalkDog.54138969', 'frame_1301.jpg']], dtype='<U16'), array([['S11', 'Purchases 1.58860488', 'frame_221.jpg']], dtype='<U20'), array([['S5', 'Waiting 2.54138969', 'frame_4781.jpg']], dtype='<U18'), array([['S5', 'Phoning.60457274', 'frame_1721.jpg']], dtype='<U16')]\n"]}],"source":["%run main/data_generator.ipynb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9568,"status":"ok","timestamp":1638873346081,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"},"user_tz":420},"id":"RMkFezS5Ly0G","outputId":"6445ddc8-29d0-46ca-b3ca-1866210993e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["importing Jupyter notebook from model.ipynb\n","Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.3.2)\n","Requirement already satisfied: PyPI in /usr/local/lib/python3.7/dist-packages (2.1)\n","Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.4.12)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n"]}],"source":["from model import *\n","# from model import VideoTransformer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nVfVFBOWWcEz"},"outputs":[],"source":["receptive_field = 8\n","# initialize the model\n","model_pos_train = VideoTransformer(num_frame=receptive_field, in_chans = 82, embed_dim_ratio = 16, num_heads=8, mlp_ratio=2., qkv_bias=True, qk_scale=None, drop_path_rate=0.1)\n","model_pos = VideoTransformer(num_frame=receptive_field, in_chans = 82, embed_dim_ratio = 16, num_heads=8, mlp_ratio=2., qkv_bias=True, qk_scale=None, drop_path_rate=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1638873347179,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"},"user_tz":420},"id":"wbkgBITaqsZV","outputId":"1ed961fa-bedd-4f10-f388-52419de2b896"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO: Trainable paramter count: 55373051\n"]}],"source":["# count the trainable paramters\n","model_params = 0\n","for parameter in model_pos_train.parameters():\n","  model_params += parameter.numel()\n","print('INFO: Trainable paramter count:', model_params)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yOXVXjR8rHyY"},"outputs":[],"source":["# convert the data structure to cuda\n","if torch.cuda.is_available():\n","  model_pos_train = nn.DataParallel(model_pos_train)\n","  model_pos_train = model_pos_train.cuda()\n","  model_pos = nn.DataParallel(model_pos)\n","  model_pos = model_pos.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U0mtMuVDrbFE"},"outputs":[],"source":["# resume\n","# args.resume = 'epoch_50.bin'   # change this argument to resume the train or start a new training\n","\n","if args.resume or args.evaluate:\n","  chk_filename = os.path.join(args.checkpoint, args.resume if args.resume else args.evaluate)      # check point filename\n","  print('Loading Checkpoint', chk_filename)\n","  checkpoint = torch.load(chk_filename, map_location=lambda storage, loc: storage)\n","  model_pos_train.load_state_dict(checkpoint['model_pos'], strict=False)\n","  model_pos.load_state_dict(checkpoint['model_pos'], strict=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8588,"status":"ok","timestamp":1638873358888,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"},"user_tz":420},"id":"wuKioeENMWoT","outputId":"fd89496c-d9ef-4ab1-f1de-fb575710bea2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/HME/Temporal-Transformer\n","Requirement already satisfied: trimesh in /usr/local/lib/python3.7/dist-packages (3.9.35)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from trimesh) (1.19.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from trimesh) (57.4.0)\n","***** LOGDIR*****:   /data/ssd1/russales/logs/07122021-103557\n","***** LOGDIR*****:   /data/ssd1/russales/logs/07122021-103557\n"]}],"source":["%run main/transformation.ipynb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1638873358889,"user":{"displayName":"Zhaoxiang Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10349876649929505294"},"user_tz":420},"id":"wYruSOaqP9mz","outputId":"6c993985-483d-425c-dcb2-84d49b1384f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/HME/Temporal-Transformer\n"]}],"source":["%cd /content/drive/MyDrive/HME/Temporal-Transformer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qmfkJaVCPHeL"},"outputs":[],"source":["# %run hmr.2.ipynb\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wp9RwM4f9Wlx"},"outputs":[],"source":["%run main/loss.ipynb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"YFyYgwO5ryp6","outputId":"3accfdb1-9425-48da-8910-32c3b9451be7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading dataset.....\n","number of batches in an epoch:  142\n","current epoch  0\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(1.5883, device='cuda:0')\n","rm: cannot remove 'Training Loss.png': No such file or directory\n","tensor(2.4518, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/best_epoch.bin\n","current epoch  1\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(1.2062, device='cuda:0')\n","tensor(1.3684, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/best_epoch.bin\n","current epoch  2\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(1.0737, device='cuda:0')\n","tensor(1.1508, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/best_epoch.bin\n","current epoch  3\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(1.0634, device='cuda:0')\n","tensor(1.0750, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/best_epoch.bin\n","current epoch  4\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(1.0100, device='cuda:0')\n","tensor(1.0367, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/best_epoch.bin\n","current epoch  5\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9858, device='cuda:0')\n","tensor(1.0139, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/best_epoch.bin\n","current epoch  6\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9659, device='cuda:0')\n","tensor(0.9906, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/best_epoch.bin\n","current epoch  7\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9555, device='cuda:0')\n","tensor(0.9749, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/best_epoch.bin\n","current epoch  8\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9431, device='cuda:0')\n","tensor(0.9601, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/best_epoch.bin\n","current epoch  9\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9346, device='cuda:0')\n","tensor(0.9567, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/best_epoch.bin\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/epoch_10.bin\n","current epoch  10\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9409, device='cuda:0')\n","tensor(0.9412, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  11\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9682, device='cuda:0')\n","tensor(0.9416, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  12\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9235, device='cuda:0')\n","tensor(0.9327, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/best_epoch.bin\n","current epoch  13\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9028, device='cuda:0')\n","tensor(0.9258, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/best_epoch.bin\n","current epoch  14\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9014, device='cuda:0')\n","tensor(0.9063, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/best_epoch.bin\n","current epoch  15\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8928, device='cuda:0')\n","tensor(0.9093, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/best_epoch.bin\n","current epoch  16\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8937, device='cuda:0')\n","tensor(0.8974, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  17\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8952, device='cuda:0')\n","tensor(0.8925, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  18\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9091, device='cuda:0')\n","tensor(0.8938, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  19\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8854, device='cuda:0')\n","tensor(0.8926, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/best_epoch.bin\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/epoch_20.bin\n","current epoch  20\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8934, device='cuda:0')\n","tensor(0.8947, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  21\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8945, device='cuda:0')\n","tensor(0.8916, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  22\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8725, device='cuda:0')\n","tensor(0.8866, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/best_epoch.bin\n","current epoch  23\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8896, device='cuda:0')\n","tensor(0.8807, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  24\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9022, device='cuda:0')\n","tensor(0.8724, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  25\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8946, device='cuda:0')\n","tensor(0.8762, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  26\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8782, device='cuda:0')\n","tensor(0.8693, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  27\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8864, device='cuda:0')\n","tensor(0.8904, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  28\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8861, device='cuda:0')\n","tensor(0.8759, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  29\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8897, device='cuda:0')\n","tensor(0.8681, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/epoch_30.bin\n","current epoch  30\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8882, device='cuda:0')\n","tensor(0.8747, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  31\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8936, device='cuda:0')\n","tensor(0.8614, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  32\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8742, device='cuda:0')\n","tensor(0.8649, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  33\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8899, device='cuda:0')\n","tensor(0.8557, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  34\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8778, device='cuda:0')\n","tensor(0.8621, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  35\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8894, device='cuda:0')\n","tensor(0.8510, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  36\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8842, device='cuda:0')\n","tensor(0.8493, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  37\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8849, device='cuda:0')\n","tensor(0.8427, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  38\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8823, device='cuda:0')\n","tensor(0.8457, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  39\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8829, device='cuda:0')\n","tensor(0.8487, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/epoch_40.bin\n","current epoch  40\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8938, device='cuda:0')\n","tensor(0.8485, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  41\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8917, device='cuda:0')\n","tensor(0.8543, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  42\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8910, device='cuda:0')\n","tensor(0.8463, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  43\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8849, device='cuda:0')\n","tensor(0.8304, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  44\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8927, device='cuda:0')\n","tensor(0.8314, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  45\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8727, device='cuda:0')\n","tensor(0.8302, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  46\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8910, device='cuda:0')\n","tensor(0.8240, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  47\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8855, device='cuda:0')\n","tensor(0.8280, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  48\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8842, device='cuda:0')\n","tensor(0.8265, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  49\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8985, device='cuda:0')\n","tensor(0.8182, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/epoch_50.bin\n","current epoch  50\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8815, device='cuda:0')\n","tensor(0.8165, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  51\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8845, device='cuda:0')\n","tensor(0.8113, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  52\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8860, device='cuda:0')\n","tensor(0.8146, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  53\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8877, device='cuda:0')\n","tensor(0.8074, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  54\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9037, device='cuda:0')\n","tensor(0.8068, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  55\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8941, device='cuda:0')\n","tensor(0.8080, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  56\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9040, device='cuda:0')\n","tensor(0.7956, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  57\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9118, device='cuda:0')\n","tensor(0.7955, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  58\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8985, device='cuda:0')\n","tensor(0.7855, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  59\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8794, device='cuda:0')\n","tensor(0.7904, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/epoch_60.bin\n","current epoch  60\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8876, device='cuda:0')\n","tensor(0.7775, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  61\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8978, device='cuda:0')\n","tensor(0.7711, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  62\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9011, device='cuda:0')\n","tensor(0.7643, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  63\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8954, device='cuda:0')\n","tensor(0.7626, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  64\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8878, device='cuda:0')\n","tensor(0.7539, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  65\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9069, device='cuda:0')\n","tensor(0.7565, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  66\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9097, device='cuda:0')\n","tensor(0.7593, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  67\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.8950, device='cuda:0')\n","tensor(0.7552, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  68\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9219, device='cuda:0')\n","tensor(0.7442, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  69\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9083, device='cuda:0')\n","tensor(0.7536, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/epoch_70.bin\n","current epoch  70\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9059, device='cuda:0')\n","tensor(0.7379, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  71\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9051, device='cuda:0')\n","tensor(0.7328, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  72\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9051, device='cuda:0')\n","tensor(0.7227, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  73\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9005, device='cuda:0')\n","tensor(0.7201, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  74\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9112, device='cuda:0')\n","tensor(0.7093, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  75\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9022, device='cuda:0')\n","tensor(0.6993, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  76\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9223, device='cuda:0')\n","tensor(0.6904, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  77\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9108, device='cuda:0')\n","tensor(0.6869, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  78\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9116, device='cuda:0')\n","tensor(0.6865, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  79\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9150, device='cuda:0')\n","tensor(0.6758, device='cuda:0', grad_fn=<DivBackward0>)\n","Saving checkpoint to checkpoint/embed_dim16_lr_0.001/epoch_80.bin\n","current epoch  80\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9049, device='cuda:0')\n","tensor(0.6727, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  81\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9228, device='cuda:0')\n","tensor(0.6596, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  82\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9449, device='cuda:0')\n","tensor(0.6508, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  83\n","dividing data......\n","dividing data......\n","validation error for current epoch is:   tensor(0.9259, device='cuda:0')\n","tensor(0.6498, device='cuda:0', grad_fn=<DivBackward0>)\n","current epoch  84\n","dividing data......\n"]}],"source":["# train and validate\n","## load dataset\n","print('Loading dataset.....')\n","dataset_path = '/content/drive/MyDrive/HME/Temporal-Transformer/trainingdata.npy'\n","# args.dataset should be the name of the npz file\n","data = np.load(dataset_path, allow_pickle=True)\n","n_batch = len(data) // args.batch_size\n","print('number of batches in an epoch: ', n_batch)\n","dataloader = Dataloader_zzx_central_gt(data, batch_size=512)\n","args.epochs = 200\n","\n","\n","# test initialize\n","testset_path = '/content/drive/MyDrive/HME/Temporal-Transformer/test_data.npy'\n","# args.dataset should be the name of the npz file\n","\n","test_data = np.load(testset_path, allow_pickle=True)\n","n_test_batch = len(test_data) // args.batch_size\n","dataloader_test = Dataloader_zzx_central_gt(test_data, batch_size=512)\n","error = 0\n","\n","\n","# check is epoch is defined\n","if 'epoch' not in locals():\n","    epoch = 0   # else it remains the same with \n","\n","# lr = args.learning_rate\n","lr = 0.001\n","\n","if 'losses' not in locals():\n","    losses = []   # store all the loss\n","\n","if 'errors' not in locals():\n","    errors = []\n","\n","optimizer = optim.AdamW(model_pos_train.parameters(), lr=lr, weight_decay=0.1)\n","\n","best_epoch_error = 100\n","\n","\n","## training\n","while epoch < args.epochs:\n","  print('current epoch ', epoch)\n","  epoch_loss = 0\n","  error = 0\n","  model_pos_train.train()\n","  for j, central_gt in dataloader.generator():\n","      if torch.cuda.is_available():\n","          central_gt = central_gt.cuda()\n","          j = j.cuda()\n","          # print('yes')\n","          predict = model_pos_train(j)\n","\n","      else:\n","          predict = model_pos_train(j)\n","      \n","      optimizer.zero_grad()       # clear all the gradiants before each batch iteration\n","      \n","      loss = torch.mean(torch.norm((predict.squeeze() - central_gt.squeeze()), dim = 1))\n","\n","      loss.backward()\n","\n","      optimizer.step()\n","\n","      epoch_loss = epoch_loss + loss\n","\n","  # end of epoch validation\n","  with torch.no_grad():\n","      error = 0\n","      model_pos.load_state_dict(model_pos_train.state_dict(), strict=False)\n","      model_pos.eval()\n","        # change the args definition in argumentation\n","\n","      for j, central_gt in dataloader_test.generator():\n","          if torch.cuda.is_available():\n","              central_gt = central_gt.cuda()\n","              j = j.cuda()\n","              # print('yes')\n","              predict = model_pos_train(j)\n","\n","          error_batch = torch.mean(torch.norm((predict.squeeze() - central_gt.squeeze()), dim = 1))\n","\n","          error += error_batch\n","  \n","  print('validation error for current epoch is:  ', error/n_test_batch)\n","\n","\n","  losses.append(epoch_loss/n_batch)\n","  errors.append(error/n_test_batch)\n","  !rm Training\\ Loss.png\n","  train_plot(losses)\n","  test_plot(errors)\n","  print(epoch_loss/n_batch)\n","  epoch += 1\n","\n","\n","  # save the model\n","# args.checkpoint_frequency = 10\n","  if best_epoch_error > error/n_test_batch:\n","      best_epoch_error = error/n_test_batch\n","\n","      chk_path = os.path.join(args.checkpoint, 'embed_dim16_lr_0.001', 'best_epoch.bin'.format(epoch))\n","      print('Saving checkpoint to', chk_path)\n","      torch.save({\n","          'epoch': epoch,\n","          'lr': lr,\n","          'optimizer': optimizer.state_dict(),\n","          'model_pos': model_pos_train.state_dict(),\n","          # 'model_traj': model_traj_train.state_dict() if semi_supervised else None,\n","          # 'random_state_semi': semi_generator.random_state() if semi_supervised else None,\n","      }, chk_path)\n","  if epoch % args.checkpoint_frequency == 0:\n","      chk_path = os.path.join(args.checkpoint, 'embed_dim16_lr_0.001', 'epoch_{}.bin'.format(epoch))\n","      print('Saving checkpoint to', chk_path)\n","\n","      torch.save({\n","          'epoch': epoch,\n","          'lr': lr,\n","          'optimizer': optimizer.state_dict(),\n","          'model_pos': model_pos_train.state_dict(),\n","          # 'model_traj': model_traj_train.state_dict() if semi_supervised else None,\n","          # 'random_state_semi': semi_generator.random_state() if semi_supervised else None,\n","      }, chk_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5FZvXldlyZPL"},"outputs":[],"source":["# train with 3D GT\n","# from main.loss import loss_compute\n","import torch\n","## load dataset\n","print('Loading dataset.....')\n","dataset_path = '/content/drive/MyDrive/HME/Temporal-Transformer/trainingdata.npy'\n","# args.dataset should be the name of the npz file\n","data = np.load(dataset_path, allow_pickle=True)\n","n_batch = len(data) // args.batch_size\n","print('number of batches in an epoch: ', n_batch)\n","dataloader = Dataloader_zzx_central_hm36_gt_tag(data, batch_size=512)\n","args.epochs = 200\n","\n","\n","# test initialize\n","testset_path = '/content/drive/MyDrive/HME/Temporal-Transformer/test_data.npy'\n","# args.dataset should be the name of the npz file\n","\n","test_data = np.load(testset_path, allow_pickle=True)\n","n_test_batch = len(test_data) // args.batch_size\n","dataloader_test = Dataloader_zzx_central_hm36_gt_tag(test_data, batch_size=512)\n","error = 0\n","\n","\n","# check is epoch is defined\n","if 'epoch' not in locals():\n","    epoch = 0   # else it remains the same with \n","\n","lr = args.learning_rate\n","# lr = 0.0001\n","\n","if 'losses' not in locals():\n","    losses = []   # store all the loss\n","\n","if 'errors' not in locals():\n","    errors = []\n","\n","optimizer = optim.AdamW(model_pos_train.parameters(), lr=lr, weight_decay=0.1)\n","\n","best_epoch_error = 10000000\n","\n","\n","## training\n","while epoch < args.epochs:\n","  print('current epoch ', epoch)\n","  epoch_loss = 0\n","  epoch_loss1 = 0\n","  epoch_loss2 = 0\n","  error = 0\n","  model_pos_train.train()\n","  for j, central_gt, gt_3d, cams, name in dataloader.generator():\n","      if torch.cuda.is_available():\n","          central_gt = central_gt.cuda()\n","          j = j.cuda()\n","          # print('yes')\n","          predict = model_pos_train(j)\n","\n","      else:\n","          predict = model_pos_train(j)\n","      \n","      optimizer.zero_grad()       # clear all the gradiants before each batch iteration\n","      \n","      loss, loss1, loss2 = loss_compute_grad(predict, central_gt, gt_3d, epoch)\n","      \n","      \n","      loss.backward()\n","\n","      optimizer.step()\n","\n","      epoch_loss = epoch_loss + loss\n","      epoch_loss1 = epoch_loss1 + loss1\n","      epoch_loss2 = epoch_loss2 + loss2\n","  \n","  print(\" The total loss is: \", epoch_loss/n_batch, '\\n', 'The smpl loss is: ', epoch_loss1/n_batch, '\\n', 'The 3D joints loss is: ', epoch_loss2/n_batch)\n","\n","  # end of epoch validation\n","  with torch.no_grad():\n","      error = 0\n","      model_pos.load_state_dict(model_pos_train.state_dict(), strict=False)\n","      model_pos.eval()\n","        # change the args definition in argumentation\n","\n","      for j, central_gt, gt_3d, cams, name in dataloader_test.generator():\n","          if torch.cuda.is_available():\n","              central_gt = central_gt.cuda()\n","              j = j.cuda()\n","              # print('yes')\n","              predict = model_pos_train(j)\n","\n","          # error_batch = torch.mean(torch.norm((predict.squeeze() - central_gt.squeeze()), dim = 1))\n","          error_batch = mpjpe(predict, central_gt, gt_3d)\n","\n","          error += error_batch\n","  \n","  print('validation error for current epoch is:  ', error/n_test_batch)\n","\n","\n","  losses.append(epoch_loss/n_batch)\n","  errors.append(error/n_test_batch)\n","  !rm Training\\ Loss.png\n","  train_plot(losses)\n","  test_plot(errors)\n","  epoch += 1\n","\n","\n","  # save the model\n","# args.checkpoint_frequency = 10\n","  if best_epoch_error > error/n_test_batch:\n","      best_epoch_error = error/n_test_batch\n","\n","      chk_path = os.path.join(args.checkpoint, 'embed_3D_growth_dim16_lr_0.001', 'best_epoch.bin'.format(epoch))\n","      print('Saving checkpoint to', chk_path)\n","      torch.save({\n","          'epoch': epoch,\n","          'lr': lr,\n","          'optimizer': optimizer.state_dict(),\n","          'model_pos': model_pos_train.state_dict(),\n","          # 'model_traj': model_traj_train.state_dict() if semi_supervised else None,\n","          # 'random_state_semi': semi_generator.random_state() if semi_supervised else None,\n","      }, chk_path)\n","  if epoch % args.checkpoint_frequency == 0:\n","      chk_path = os.path.join(args.checkpoint, 'embed_3D_growth_dim16_lr_0.001', 'epoch_{}.bin'.format(epoch))\n","      print('Saving checkpoint to', chk_path)\n","\n","      torch.save({\n","          'epoch': epoch,\n","          'lr': lr,\n","          'optimizer': optimizer.state_dict(),\n","          'model_pos': model_pos_train.state_dict(),\n","          # 'model_traj': model_traj_train.state_dict() if semi_supervised else None,\n","          # 'random_state_semi': semi_generator.random_state() if semi_supervised else None,\n","      }, chk_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"61JERw7ebFVC"},"outputs":[],"source":["## visualization for one specific video\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k8CUCYUBU6Eo"},"outputs":[],"source":["# visualization\n","# render the smpl model with the prediction output\n","index = 0\n","dataloader = Dataloader_zzx_central_gt_frame(data, batch_size=1)\n","\n","# load the data for only one batch\n","for sample, central, name in dataloader.generator():\n","    print(sample.shape)\n","    break\n","\n","with torch.no_grad():\n","      error = 0\n","      model_pos.load_state_dict(model_pos_train.state_dict(), strict=False)\n","      model_pos.eval()\n","        # change the args definition in argumentation\n","      if torch.cuda.is_available():\n","          central = central.cuda()\n","          sample = sample.cuda()\n","          # print('yes')\n","          predict = model_pos(sample)\n","\n","print(predict.shape)\n","# the shape is correct\n","\n","shape_and_pose = predict.cpu().detach().numpy()\n","\n","central = central.cpu().detach().numpy()\n","\n","# convert torch.cuda to numpy\n","## convert the predicted pose_and_shape to vertices\n","shape_and_pose = np.expand_dims(shape_and_pose.squeeze(), axis = 0)\n","central = np.expand_dims(central.squeeze(), axis = 0)\n","\n","vertices, joints_3d, shapes = smpl2vertices(shape_and_pose)\n","vertices_gt, joints_3d_gt, shapes_gt = smpl2vertices(central)\n","\n","vertices = vertices.numpy()\n","vertices_gt = vertices_gt.numpy()\n","# print(type(vertices))\n","vertices = vertices.squeeze()\n","vertices_gt = vertices_gt.squeeze()\n","\n","np.save('vertices', vertices)\n","np.save('vertices_gt', vertices_gt)\n","np.save('name', name)\n","print(name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"156U9iu7oDFn"},"outputs":[],"source":["# check the prediction and central input\n","\n","# print(central[0], '\\n', predict[0])\n","print(predict[0,0,0])\n","print(predict)\n","print(central_gt)\n","print(predict[0].squeeze() - central_gt[0].squeeze())\n","# torch.norm((predict[0].squeeze() - central_gt[0].squeeze()), dim = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-akNdX9L_vzp"},"outputs":[],"source":["# plot the training loss\n","\n","train_plot(losses)\n","test_plot(errors)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WaDEd1N1Quq-"},"outputs":[],"source":["min(errors)"]},{"cell_type":"markdown","metadata":{"id":"6oZzSOZ6kj3c"},"source":["# **Some modules that can be used**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IK36AKW3QxbC"},"outputs":[],"source":["## load dataset\n","print('Loading dataset.....')\n","dataset_path = '/content/drive/MyDrive/HME/Temporal-Transformer/trainingdata.npy'\n","# args.dataset should be the name of the npz file\n","\n","data = np.load(dataset_path, allow_pickle=True)\n","n_batch = len(data) // args.batch_size\n","print('number of batches in an epoch: ', n_batch)\n","dataloader = Dataloader_zzx_central_gt(data, batch_size=512)\n","args.epochs = 200\n","\n","# check is epoch is defined\n","if 'epoch' not in locals():\n","    epoch = 0   # else it remains the same with \n","\n","lr = args.learning_rate\n","\n","if 'losses' not in locals():\n","    losses = []   # store all the loss\n","\n","optimizer = optim.AdamW(model_pos_train.parameters(), lr=lr, weight_decay=0.1)\n","\n","\n","## training\n","while epoch < args.epochs:\n","  print('current epoch ', epoch)\n","  epoch_loss = 0\n","  model_pos_train.train()\n","  for j, central_gt in dataloader.generator():\n","      if torch.cuda.is_available():\n","          central_gt = central_gt.cuda()\n","          j = j.cuda()\n","          # print('yes')\n","          predict = model_pos_train(j)\n","\n","      else:\n","          predict = model_pos_train(j)\n","      \n","      optimizer.zero_grad()       # clear all the gradiants before each batch iteration\n","      \n","      loss = torch.mean(torch.norm((predict.squeeze() - central_gt.squeeze()), dim = 1))\n","\n","      loss.backward()\n","\n","      optimizer.step()\n","\n","      epoch_loss = epoch_loss + loss\n","  \n","  losses.append(epoch_loss/n_batch)\n","  !rm Training\\ Loss.png\n","  train_plot(losses)\n","  print(epoch_loss/n_batch)\n","  epoch += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2CGuWr9jlHl7"},"outputs":[],"source":["# test the model\n","testset_path = '/content/drive/MyDrive/HME/Temporal-Transformer/test_data.npy'\n","# args.dataset should be the name of the npz file\n","\n","test_data = np.load(testset_path, allow_pickle=True)\n","n_test_batch = len(test_data) // args.batch_size\n","dataloader_test = Dataloader_zzx_central_gt(test_data, batch_size=512)\n","error = 0\n","\n","with torch.no_grad():\n","    model_pos.load_state_dict(model_pos_train.state_dict(), strict=False)\n","    model_pos.eval()\n","      # change the args definition in argumentation\n","\n","    for j, central_gt in dataloader_test.generator():\n","        if torch.cuda.is_available():\n","            central_gt = central_gt.cuda()\n","            j = j.cuda()\n","            # print('yes')\n","            predict = model_pos_train(j)\n","\n","        error_batch = torch.mean(torch.norm((predict.squeeze() - central_gt.squeeze()), dim = 1))\n","        # print(error_batch)\n","        error += error_batch\n","\n","print(error/n_test_batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uJDPHzpVksB4"},"outputs":[],"source":["# visualization\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qYSZXOrLdSpT"},"outputs":[],"source":["## convert predicted 'shape_and_pose' to 3D joints: check the number\n","from main import model_util\n","from main.config import Config\n","from main.smpl import Smpl\n","import numpy as np\n","\n","print(predict.shape)\n","\n","# use the smpl function\n","smpl = Smpl()\n","\n","# vertices, joints_3d, rotations = smpl(pose_and_shape, **kwargs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0To1KyFSouEM"},"outputs":[],"source":["dataset_path = '/content/drive/MyDrive/HME/Temporal-Transformer/trainingdata.npy'\n","# args.dataset should be the name of the npz file\n","\n","data = np.load(dataset_path, allow_pickle=True)\n","# data = data.transpose()\n","len(data) // 512"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1cXF238uXrmR"},"outputs":[],"source":["A = torch.ones(2,1,3)\n","A\n","B = torch.zeros(2,1,3)\n","torch.mean(torch.norm((A.squeeze() - B.squeeze()), dim = 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5uk2NYSYTb36"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3v5if4gSgG1P"},"outputs":[],"source":["predict.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zk-PMR5iGVGk"},"outputs":[],"source":["# don't know if uses?\n","\n","def eval_data_prepare(receptive_field, inputs_2d, inputs_3d):\n","  inputs_2d_p = torch.squeeze(inputs_2d)\n","  inputs_3d_p = inputs_3d.permute(1, 0, 2, 3)\n","  out_num = inputs_2d_p.shape[0] - receptive_field + 1\n","  eval_input_2d = torch.empty(out_num, receptive_field, inputs_2d_p.shape[1], inputs_2d_p.shape[2])\n","  for i in range(out_num):\n","    eval_input_2d[i, :, :, :] = inputs_2d_p[i: i + receptive_field, :, :]\n","    return eval_input_2d, inputs_3d_p\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S-AP4ML_Hjsm"},"outputs":[],"source":["# load the training data using ChunkedGenerator\n","# cameras_train, poses_train, poses_train_2d = fetch(subjects_train, action_filter, subset = args.subset)\n","# fetch function is defined above\n","\n","lr = args.learning_rate\n","optimizer = optim.AdamW(model_pos_train.parameters(), lr = lr, weight_decay=0.1)\n","\n","lr_decay = args.lr_decay\n","losses_3d_train = []\n","losses_3d_train_eval = []\n","losses_3d_valid = []\n","\n","epoch = 0\n","initial_momentum = []\n","final_momentum = []\n","\n","train_generator = ChunkedGenerator(args.batch_size, camera_train, poses_train, pose_train_2d, args.stride,\n","                                    pad = pad, causal_shift = causal_shift, shuffle = True, augment=args.data_augmentation,\n","                                    kps_left=kps_left, kps_right=kps_right, joints_left=joints_left, joints_right=joints_right)\n","\n","train_generator_eval = UnchunkedGenerator(cameras_train,poses_train,poses_train_2d,\n","                                          pad=pad, causal_shift=causal_shift, augment=False)\n","\n","print('INFO: Training on {} frames'.format(train_generator_eval.num_frames()))\n","\n","if args.resume:\n","  epoch = checkpoint['epoch']\n","  if 'optimizer' in checkpoint and checkpoint['optimizer'] in not None:\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","    train_generator.set_random_state(checkpoint['random_state'])\n","  \n","  else:\n","    print('WARNING: this checkpoint does not contain an optimizer state. the optimizer will be reinitialized.')\n","\n","  lr = checkpoint['lr']\n","\n","print('** Note: reported losses are averaged over all frames.')\n","print('** The final evaluation will be carried out after the last training epoch')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XW3K3B5SOrPh"},"outputs":[],"source":["# training\n","while epoch < args.epochs:\n","    print('current epoch:   ', epoch)\n","    start_time = time()\n","    epoch_loss_3d_train = 0\n","    epoch_loss_traj_train = 0\n","    epoch_loss_2d_train_unlabeled = 0\n","    N = 0\n","    N_semi = 0\n","    model_pos_train.train()       # tell the model that it's traing, some of the layers would function differently\n","\n","    for cameras_train, batch_3d, batch_2d, smpl in train_generator.next_epoch():\n","      cameras_train = torch.from_numpy(camera_train.astype('float32'))\n","      inputs_3d = torch.from_numpy(batch_3d.astype('float32'))\n","      inputs_2d = torch.from_numpy(batch_2d.astype('float32'))\n","      smpl = torch.from_numpy(smpl.astype('float32'))\n","\n","      if torch.cuda.is_available():\n","          inputs_3d = inputs_3d.cuda()\n","          inputs_2d = inputs_2d.cuda()\n","          cameras_train = cameras_train.cuda()\n","      inputs_traj = inputs_3d[:, :, :1].clone()\n","      inputs_3d[:, :, 0] = 0\n","\n","      optimizer.zero_grad()\n","\n","      # Predict 3D poses\n","      predicted_3d_pos = model_pos_train(inputs_2d)\n","      \n","      del inputs_2d_p\n","      torch.cuda.empty_cache()\n","\n","      loss_3d_poses = mpjpe(predicted_3d_pos, inputs_3d)\n","      epoch_loss_3d_train += inputs_3d.shape[0] * inputs_3d.shape[1] * loss_3d_pos.item()\n","      N += inputs_3d.shape[0] * inputs_3d.shape[1]\n","\n","      loss_total = loss_3d_pos\n","\n","      loss_total.backward()\n","\n","      optimizer.step()\n","\n","      del inputs_3d, loss_3d_pos, predicted_3d_pos\n","      torch.cuda.empty_cache()\n","    \n","    loss_3d_train.append(epoch_loss_3d_train / N)\n","\n","    # print the result in every epoch\n","    print('[%d] time %.2f lr % f 3d_train %f' %(\n","        epoch + 1,\n","        elapsed,\n","        lr,\n","        losses_3d_train[-1]     # loss in nearest epoch\n","    ))\n"]},{"cell_type":"markdown","metadata":{"id":"cXGeTOM4Uj7Z"},"source":["**Lack of evaluation within epochs, and the validation after the training is done.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W7cC_Rawi20D"},"outputs":[],"source":["# save the model\n","\n","# args.checkpoint_frequency = 10\n","if epoch % args.checkpoint_frequency == 0:\n","    chk_path = os.path.join(args.checkpoint, 'epoch_{}.bin'.format(epoch))\n","    print('Saving checkpoint to', chk_path)\n","\n","    torch.save({\n","        'epoch': epoch,\n","        'lr': lr,\n","        'optimizer': optimizer.state_dict(),\n","        'model_pos': model_pos_train.state_dict(),\n","        # 'model_traj': model_traj_train.state_dict() if semi_supervised else None,\n","        # 'random_state_semi': semi_generator.random_state() if semi_supervised else None,\n","    }, chk_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-coDejO5oOGX"},"outputs":[],"source":["# clear all the variables\n","\n","%reset"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Run_VideoFormer.ipynb","provenance":[],"authorship_tag":"ABX9TyMmxXt5nHtkJwyF7KimCaeE"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}